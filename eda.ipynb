{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set is from [circl-phishing-dataset-01](https://www.circl.lu/opendata/datasets/circl-phishing-dataset-01/), Introduction [here](https://www.circl.lu/opendata/circl-phishing-dataset-01/).\n",
    "\n",
    "It contains 457 phishing webpage screenshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: circl_phishing_dataset/Clean_phishing_references.json\n",
      "Downloaded: circl_phishing_dataset/ground_truth_dataturks.json\n",
      "Downloaded: circl_phishing_dataset/ground_truth_visjs.json\n",
      "Downloaded: circl_phishing_dataset/labels_dataturks.txt\n",
      "Downloaded: circl_phishing_dataset/visjs_graph.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the dataset page\n",
    "url = \"https://www.circl.lu/opendata/datasets/circl-phishing-dataset-01/\"\n",
    "\n",
    "# Directory to save the downloaded files\n",
    "output_dir = \"circl_phishing_dataset\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def download_file(file_url, save_path):\n",
    "    \"\"\"Download a file from a URL.\"\"\"\n",
    "    response = requests.get(file_url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        print(f\"Downloaded: {save_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {file_url} (Status code: {response.status_code})\")\n",
    "\n",
    "# Scrape the page to find downloadable files\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    # Find all links to downloadable files\n",
    "    for link in soup.find_all(\"a\", href=True):\n",
    "        file_link = link[\"href\"]\n",
    "        if file_link.endswith((\".json\",\".txt\")):  \n",
    "            file_url = url + file_link if not file_link.startswith(\"http\") else file_link\n",
    "            file_name = os.path.basename(file_link)\n",
    "            download_file(file_url, os.path.join(output_dir, file_name))\n",
    "else:\n",
    "    print(f\"Failed to access the URL: {url} (Status code: {response.status_code})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: circl_phishing_dataset/Clean_phishing/abashed-careless-ordinary-crew.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/ablaze-jazzy-tangy-file.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/ablaze-lean-grubby-particular.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/able-yellow-defective-variety.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/abstracted-colossal-rich-race.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/abstracted-excellent-plastic-insect.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/abundant-various-adjoining-tap.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/abusive-gabby-statuesque-nurse.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/accidental-eager-grumpy-writer.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/accurate-scintillating-picayune-administration.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/adamant-accidental-hellish-feature.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/adamant-spicy-absurd-economics.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/adhesive-concerned-expensive-competition.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/adhoc-racial-condemned-letter.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/adjoining-handsomely-female-scene.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/adventurous-sleepy-public-joke.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/aggressive-defiant-imminent-bottle.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/alike-idiotic-shy-fail.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/alleged-abashed-clumsy-life.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/amazing-daily-handy-speech.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/ambitious-curious-picayune-shock.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/amuck-perpetual-rightful-control.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/angry-puffy-sick-pin.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/angry-victorious-pricey-proof.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/ashamed-robust-acrid-physics.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/aspiring-assorted-bumpy-highway.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/aspiring-repulsive-good-camera.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/astonishing-premium-complete-love.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/attractive-maddening-romantic-sort.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/auspicious-fragile-cute-corner.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/available-satisfying-spiky-black.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/aware-difficult-foamy-nurse.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/awesome-complete-overwrought-platform.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/awesome-neighborly-black-wonder.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/awful-nasty-heartbreaking-appointment.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/beautiful-brown-flat-shoe.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/beautiful-earsplitting-plastic-management.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/belligerent-nine-delicious-ground.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/best-labored-penitent-copy.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/best-rural-wise-design.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/better-smart-opposite-television.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/blushing-furry-tiresome-highlight.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/brainy-colorful-tightfisted-south.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/brief-obscene-huge-discount.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/bright-delicious-apathetic-distance.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/bright-embarrassed-venomous-hair.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/bright-oceanic-old-grab.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/bright-wiry-silly-shelter.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/broad-round-unbecoming-scheme.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/broad-sweet-cooing-newspaper.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/cagey-stereotyped-wholesale-society.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/calculating-protective-creepy-look.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/careless-classy-vast-chest.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/ceaseless-ajar-lovely-estate.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/ceaseless-unequaled-malicious-ride.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/certain-mushy-picayune-revenue.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/charming-defeated-voracious-beat.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/cheap-curly-bad-river.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/chubby-unnatural-spurious-structure.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/clammy-lovely-demonic-guidance.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/clear-honorable-red-command.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/clear-real-clumsy-disk.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/closed-secretive-icy-issue.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/coherent-determined-sour-foot.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/cold-gaping-undesirable-training.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/colorful-macho-ratty-treat.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/colorful-phobic-shocking-army.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/common-jumbled-excited-charge.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/common-unarmed-bustling-game.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/condemned-separate-quiet-concept.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/conscious-cloistered-ablaze-health.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/cooing-soft-rotten-insurance.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/cool-dead-whispering-present.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/cowardly-willing-efficacious-poem.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/crowded-stingy-disgusting-serve.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/cultured-loud-equable-injury.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/curved-fluttering-upbeat-energy.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/cut-somber-exclusive-university.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/daffy-malicious-spiky-student.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/damaged-ratty-disgusting-square.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/dangerous-vast-big-replacement.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/dashing-delicious-insidious-science.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/dashing-wide-diligent-sad.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/deafening-boorish-imported-nothing.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/dear-curvy-known-ease.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/decisive-murky-windy-amount.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/decisive-vagabond-unknown-science.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/dependent-feigned-premium-candy.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/dependent-hellish-hurt-diet.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/determined-steadfast-spicy-kind.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/devilish-unwritten-fast-wake.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/different-glossy-smart-clock.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/dirty-debonair-gainful-strip.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/dirty-willing-brainy-plane.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/disgusting-brawny-spectacular-plate.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/dispensable-snotty-luxuriant-policy.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/divergent-vagabond-purring-response.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/dizzy-rampant-snobbish-setting.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/domineering-acid-alleged-bridge.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/dramatic-ugliest-awake-king.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/dreary-comfortable-brawny-working.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/dry-puzzling-six-fear.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/dynamic-prickly-tasteless-bus.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/eager-anxious-idiotic-topic.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/eager-smiling-substantial-support.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/economic-exultant-spurious-self.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/economic-hesitant-modern-junior.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/economic-orange-quaint-news.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/elastic-messy-cynical-catch.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/elated-woebegone-fretful-farm.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/electric-steep-tenuous-north.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/elegant-vast-ambitious-parent.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/elite-nutty-opposite-weight.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/enthusiastic-plain-resolute-bus.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/envious-pumped-flat-dream.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/exclusive-sweltering-rampant-party.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/faint-muddled-physical-husband.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/fair-shut-concerned-one.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/false-muddled-windy-view.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/fanatical-absurd-abject-cancel.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/fascinated-incandescent-silky-sport.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/fast-grouchy-snotty-bet.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/fat-noxious-doubtful-walk.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/faulty-pathetic-past-error.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/fearful-responsible-magenta-memory.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/feigned-separate-many-surround.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/festive-cagey-economic-initiative.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/fierce-aromatic-smelly-judge.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/fixed-light-tenuous-minimum.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/flagrant-comfortable-towering-juice.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/flaky-premium-wasteful-god.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/flawless-yummy-faint-occasion.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/foolish-second-orange-note.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/foolish-thoughtful-fluffy-distance.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/forgetful-panoramic-bitter-blue.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/fortunate-changeable-eatable-market.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/four-shaggy-last-essay.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/freezing-thankful-unequaled-shelter.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/frequent-rainy-clean-problem.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/fresh-tacky-inconclusive-press.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/frightened-different-likeable-sort.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/furry-unable-rotten-entertainment.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/fuzzy-nifty-disastrous-bonus.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/gainful-thinkable-boiling-piano.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/gamy-tearful-burly-church.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/garrulous-superb-luxuriant-tomorrow.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/gaudy-colossal-solid-call.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/gentle-polite-lowly-atmosphere.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/giddy-shallow-null-raw.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/goofy-obeisant-charming-role.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/graceful-nutty-wonderful-nobody.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/grandiose-forgetful-marked-initiative.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/grateful-stingy-faded-pack.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/gray-boundless-rapid-group.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/greasy-heartbreaking-married-race.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/greasy-imminent-thankful-bus.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/greasy-possible-capable-today.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/green-melodic-foamy-silly.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/groovy-far-large-sector.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/grotesque-festive-devilish-advantage.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/gruesome-silly-illustrious-grab.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/gruesome-spiteful-guarded-annual.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/gullible-excited-parallel-speed.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/guttural-xenophobic-divergent-marketing.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/habitual-aboard-handy-officer.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/habitual-ordinary-purring-shame.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/half-luxuriant-handy-depth.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/halting-abounding-vigorous-log.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/halting-weak-free-sentence.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/handsomely-marvelous-same-screen.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/handsomely-wasteful-drunk-newspaper.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/handy-second-disastrous-shopping.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/healthy-nebulous-silent-feel.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/heavy-disillusioned-unnatural-camp.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/helpful-offbeat-important-introduction.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/hesitant-curly-freezing-day.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/hesitant-harmonious-low-nature.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/hideous-marked-gratis-flow.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/highfalutin-waiting-kaput-complaint.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/hissing-mundane-waggish-fruit.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/hissing-unused-hypnotic-list.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/homely-humdrum-puffy-failure.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/hot-mature-electric-blue.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/humorous-thin-disgusted-eye.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/hurt-spiky-stormy-special.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/hushed-zany-dysfunctional-wall.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/husky-rich-crooked-debt.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/illegal-alcoholic-perfect-appeal.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/imminent-dapper-standing-personality.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/impossible-standing-vengeful-punch.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/incompetent-abnormal-funny-basis.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/inconclusive-unequal-super-clerk.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/industrious-onerous-past-smile.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/infamous-noisy-rare-bitter.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/innocent-chief-spurious-television.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/inquisitive-hellish-roomy-display.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/inquisitive-intelligent-miscreant-part.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/irritating-statuesque-poor-tooth.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/irritating-uninterested-uneven-driver.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/jazzy-spotty-fresh-bottom.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/jealous-guttural-aloof-spend.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/jealous-undesirable-jazzy-necessary.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/jobless-safe-spiky-chocolate.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/juicy-equal-rural-rock.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/juicy-ugliest-scrawny-delay.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/juvenile-waiting-adorable-mall.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/kaput-foamy-nippy-charge.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/kaput-unhealthy-rigid-system.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/kind-flippant-scary-friend.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/known-disturbed-curved-schedule.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/known-flaky-crowded-lift.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/known-present-holistic-care.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/lacking-nasty-fertile-country.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/lame-exciting-scattered-request.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/lamentable-eminent-miscreant-arm.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/learned-selfish-elfin-growth.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/legal-aspiring-sturdy-air.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/lethal-tense-voiceless-resort.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/like-overt-fantastic-profile.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/like-ready-clean-bathroom.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/likeable-innate-judicious-can.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/lively-agreeable-devilish-budget.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/lively-familiar-cheap-progress.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/lively-smart-efficient-ask.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/living-solid-ritzy-file.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/lonely-colossal-creepy-mobile.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/lopsided-actually-squealing-swim.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/low-silky-happy-double.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/luxuriant-naughty-red-football.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/magnificent-demonic-faint-recommendation.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/majestic-labored-better-pop.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/maniacal-skinny-ordinary-suggestion.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/married-imminent-sticky-following.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/materialistic-pushy-chemical-possible.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/mean-rightful-helpless-park.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/meaty-puzzled-tangy-touch.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/medical-yielding-highfalutin-tourist.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/meek-opposite-dysfunctional-implement.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/melodic-marvelous-eatable-calendar.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/melodic-organic-obsequious-stranger.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/merciful-crabby-cultured-brush.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/mere-husky-loutish-bread.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/mere-rich-youthful-training.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/mere-small-cute-wing.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/messy-soggy-purring-tomorrow.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/minor-amazing-overjoyed-nurse.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/mixed-painful-wonderful-youth.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/moldy-melted-enchanting-use.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/mountainous-bawdy-swift-grandfather.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/muddled-nice-hanging-piano.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/mundane-joyous-rough-confusion.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/murky-grateful-wacky-vacation.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/murky-wiggly-shy-piece.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/naughty-numberless-wasteful-responsibility.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/nauseating-workable-windy-sink.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/neat-alcoholic-raspy-interest.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/neat-fierce-stupendous-strain.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/nebulous-left-dashing-dimension.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/neighborly-political-stupid-due.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/nervous-past-unbiased-date.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/nice-plucky-blue-stick.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/nippy-succinct-feigned-letter.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/normal-adorable-annoyed-election.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/nostalgic-two-silly-support.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/null-hungry-wry-success.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/numerous-misty-meek-today.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/numerous-sticky-earthy-evidence.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/nutritious-incandescent-workable-handle.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/observant-plucky-lumpy-garage.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/obtainable-squeamish-demonic-protection.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/old-wet-evasive-influence.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/one-naive-filthy-membership.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/onerous-bent-voracious-ambition.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/onerous-curly-stereotyped-bathroom.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/onerous-shut-early-membership.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/open-handsomely-clean-fun.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/optimal-old-hurried-cigarette.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/orange-lyrical-gaudy-energy.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/ordinary-blushing-useful-glove.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/ossified-adamant-thinkable-window.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/ossified-puffy-fortunate-specialist.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/outgoing-irate-uptight-rub.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/overjoyed-aberrant-cluttered-shine.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/overwrought-tense-ill-possession.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/painstaking-picayune-tense-preference.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/pale-dead-sweltering-value.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/panicky-imperfect-breezy-suspect.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/parallel-pastoral-helpful-alcohol.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/parallel-stale-rainy-equipment.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/parched-cruel-silly-collar.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/parsimonious-rabid-productive-building.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/past-noiseless-accurate-stranger.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/pathetic-worthless-penitent-war.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/perpetual-long-hissing-position.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/perpetual-magenta-naive-security.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/perpetual-overjoyed-unruly-minute.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/physical-ruthless-fat-anybody.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/piquant-subsequent-dusty-make.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/placid-abhorrent-excited-entertainment.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/pleasant-far-hurt-blind.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/plucky-secret-dusty-window.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/pointless-eight-vulgar-increase.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/possessive-eager-great-priest.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/precious-unsightly-adaptable-truth.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/previous-dusty-shut-teach.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/pricey-spicy-important-cream.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/prickly-historical-tedious-perception.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/probable-necessary-grandiose-purpose.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/profuse-telling-xenophobic-interaction.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/protective-busy-rude-depression.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/psychedelic-observant-unsightly-inspector.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/psychotic-mixed-obsequious-arm.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/psychotic-odd-slimy-member.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/psychotic-thoughtful-equable-brush.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/puny-sour-foolish-active.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/quiet-insidious-nauseating-sense.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/racial-tan-wanting-steak.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/receptive-humdrum-ratty-competition.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/red-eight-chubby-mix.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/red-free-overrated-sail.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/regular-whole-square-boy.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/rich-endurable-many-ask.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/right-impartial-spicy-oil.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/righteous-super-proud-big.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/robust-drunk-rampant-trouble.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/rotten-feigned-oceanic-breast.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/rotten-young-decorous-object.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/ruddy-flagrant-tedious-trouble.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/rustic-lovely-zesty-spare.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/ruthless-worried-earthy-conflict.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/sable-entertaining-friendly-stupid.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/savory-highfalutin-slimy-control.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/scarce-aloof-different-stage.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/scarce-nervous-acrid-awareness.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/scary-homely-successful-matter.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/sedate-adorable-general-milk.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/seemly-nine-pastoral-a.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/sharp-futuristic-utopian-math.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/shrill-internal-hurried-chain.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/simplistic-nondescript-naughty-campaign.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/six-cluttered-holistic-guide.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/skinny-mundane-rampant-record.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/skinny-slow-available-post.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/sleepy-true-ten-supermarket.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/slippery-bloody-tasty-wear.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/small-sparkling-cloistered-library.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/smiling-dusty-beneficial-shoulder.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/sneaky-delicate-grumpy-character.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/soft-gullible-famous-post.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/solid-statuesque-like-recommendation.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/sore-nine-condemned-system.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/sour-curved-vivacious-egg.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/spectacular-elastic-rabid-grade.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/spiffy-succinct-lean-pay.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/spiffy-versed-irritating-extreme.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/spiteful-aback-ahead-alternative.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/spotless-determined-excellent-talk.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/spotless-ill-talented-farm.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/squealing-versed-stormy-senior.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/squeamish-offbeat-new-goal.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/statuesque-furry-damaged-two.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/statuesque-resonant-heartbreaking-weekend.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/steadfast-gaping-screeching-chicken.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/steady-mushy-lumpy-pension.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/stimulating-gratis-pointless-snow.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/stingy-deep-demonic-baseball.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/stingy-versed-kindly-client.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/striped-phobic-decisive-examination.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/striped-ultra-repulsive-spare.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/stupendous-decorous-shiny-mirror.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/stupendous-picayune-coherent-quiet.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/stupid-abaft-white-quality.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/subdued-glorious-somber-policy.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/subsequent-wooden-tasty-neat.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/substantial-quack-lumpy-media.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/substantial-responsible-needy-article.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/substantial-weary-materialistic-pollution.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/successful-irate-honorable-mobile.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/successful-unequal-inexpensive-bit.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/succinct-impossible-tedious-target.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/superb-willing-functional-flight.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/supreme-direful-cautious-agent.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/swanky-useless-eminent-charge.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/tangible-thankful-adaptable-sea.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/tangy-earsplitting-uneven-leave.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/tangy-previous-ill-drawing.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/tasteful-creepy-coherent-language.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/tasty-superficial-lively-child.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/tawdry-aware-wiggly-definition.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/tawdry-disgusting-furtive-performance.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/ten-diligent-fertile-past.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/tense-majestic-acceptable-goal.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/therapeutic-tender-fair-map.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/thick-sweet-sparkling-estate.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/thin-famous-greasy-produce.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/thin-huge-scandalous-relation.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/thinkable-nervous-private-recording.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/thinkable-omniscient-necessary-status.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/third-bewildered-smiling-north.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/third-jumpy-bent-space.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/third-quixotic-useless-student.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/thirsty-cheap-plant-award.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/thoughtful-waggish-incandescent-sign.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/thoughtless-adhesive-calm-setting.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/three-plucky-wandering-thought.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/tired-abject-ludicrous-machine.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/tiresome-green-smelly-question.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/toothsome-stingy-few-press.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/towering-meaty-nappy-entertainment.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/tranquil-afraid-changeable-post.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/tranquil-mere-pushy-snow.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/tremendous-wonderful-odd-shift.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/tricky-sturdy-impossible-sweet.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/trite-chief-noxious-ratio.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/troubled-cooperative-whole-hunt.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/truthful-lively-illustrious-local.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/typical-one-crabby-moment.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/ugliest-ugly-yummy-routine.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/ugly-squeamish-illustrious-temperature.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/unequal-tasteful-discreet-shift.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/uninterested-ignorant-smelly-pin.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/unkempt-nutty-male-platform.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/unruly-material-historical-context.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/unsightly-quaint-good-surround.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/unsuitable-feigned-harmonious-read.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/untidy-elderly-strange-end.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/utter-harsh-safe-designer.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/vacuous-vigorous-cheap-movie.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/vague-outstanding-wrong-while.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/various-abundant-moaning-cross.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/vengeful-hollow-male-writer.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/vengeful-ludicrous-tired-march.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/vengeful-rhetorical-outgoing-judge.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/venomous-agreeable-half-wonder.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/verdant-lumpy-lumpy-steal.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/voiceless-ambitious-sour-standard.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/wacky-quixotic-thirsty-combine.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/wanting-functional-goofy-possible.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/warlike-furtive-unbiased-pound.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/wicked-simplistic-dreary-lock.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/willing-grandiose-testy-zone.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/windy-sad-nine-touch.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/wiry-sudden-energetic-assignment.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/wistful-few-hushed-horse.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/wistful-rustic-interesting-memory.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/womanly-fluttering-milky-row.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/wooden-permissible-fertile-inside.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/woozy-waiting-aspiring-sex.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/worthless-boundless-voracious-aspect.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/wrathful-lyrical-alcoholic-county.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/wrathful-plant-majestic-perception.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/youthful-smiling-abrasive-lab.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/yummy-neat-frantic-sound.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/zany-cloudy-true-part.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/zealous-parsimonious-smiling-fun.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/zippy-piquant-fascinated-bag.png\n",
      "Downloaded: circl_phishing_dataset/Clean_phishing/zonked-silent-snobbish-review.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the dataset page\n",
    "url = \"https://www.circl.lu/opendata/datasets/circl-phishing-dataset-01/Clean_phishing/\"\n",
    "\n",
    "# Directory to save the downloaded files\n",
    "output_dir = \"circl_phishing_dataset/Clean_phishing\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def download_file(file_url, save_path):\n",
    "    \"\"\"Download a file from a URL.\"\"\"\n",
    "    response = requests.get(file_url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        print(f\"Downloaded: {save_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {file_url} (Status code: {response.status_code})\")\n",
    "\n",
    "# Scrape the page to find downloadable files\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    # Find all links to downloadable files\n",
    "    for link in soup.find_all(\"a\", href=True):\n",
    "        file_link = link[\"href\"]\n",
    "        if file_link.endswith((\"png\")):  # Add other extensions as needed\n",
    "            file_url = url + file_link if not file_link.startswith(\"http\") else file_link\n",
    "            file_name = os.path.basename(file_link)\n",
    "            download_file(file_url, os.path.join(output_dir, file_name))\n",
    "else:\n",
    "    print(f\"Failed to access the URL: {url} (Status code: {response.status_code})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR to extract textual content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We OCR the images, which are screenshots of phishing webpages, to extract textual content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: abashed-careless-ordinary-crew.png\n",
      "Processed: ablaze-jazzy-tangy-file.png\n",
      "Processed: ablaze-lean-grubby-particular.png\n",
      "Processed: able-yellow-defective-variety.png\n",
      "Processed: abstracted-colossal-rich-race.png\n",
      "Processed: abstracted-excellent-plastic-insect.png\n",
      "Processed: abundant-various-adjoining-tap.png\n",
      "Processed: abusive-gabby-statuesque-nurse.png\n",
      "Processed: accidental-eager-grumpy-writer.png\n",
      "Processed: accurate-scintillating-picayune-administration.png\n",
      "Processed: adamant-accidental-hellish-feature.png\n",
      "Processed: adamant-spicy-absurd-economics.png\n",
      "Processed: adhesive-concerned-expensive-competition.png\n",
      "Processed: adhoc-racial-condemned-letter.png\n",
      "Processed: adjoining-handsomely-female-scene.png\n",
      "Processed: adventurous-sleepy-public-joke.png\n",
      "Processed: aggressive-defiant-imminent-bottle.png\n",
      "Processed: alike-idiotic-shy-fail.png\n",
      "Processed: alleged-abashed-clumsy-life.png\n",
      "Processed: amazing-daily-handy-speech.png\n",
      "Processed: ambitious-curious-picayune-shock.png\n",
      "Processed: amuck-perpetual-rightful-control.png\n",
      "Processed: angry-puffy-sick-pin.png\n",
      "Processed: angry-victorious-pricey-proof.png\n",
      "Processed: ashamed-robust-acrid-physics.png\n",
      "Processed: aspiring-assorted-bumpy-highway.png\n",
      "Processed: aspiring-repulsive-good-camera.png\n",
      "Processed: astonishing-premium-complete-love.png\n",
      "Processed: attractive-maddening-romantic-sort.png\n",
      "Processed: auspicious-fragile-cute-corner.png\n",
      "Processed: available-satisfying-spiky-black.png\n",
      "Processed: aware-difficult-foamy-nurse.png\n",
      "Processed: awesome-complete-overwrought-platform.png\n",
      "Processed: awesome-neighborly-black-wonder.png\n",
      "Processed: awful-nasty-heartbreaking-appointment.png\n",
      "Processed: beautiful-brown-flat-shoe.png\n",
      "Processed: beautiful-earsplitting-plastic-management.png\n",
      "Processed: belligerent-nine-delicious-ground.png\n",
      "Processed: best-labored-penitent-copy.png\n",
      "Processed: best-rural-wise-design.png\n",
      "Processed: better-smart-opposite-television.png\n",
      "Processed: blushing-furry-tiresome-highlight.png\n",
      "Processed: brainy-colorful-tightfisted-south.png\n",
      "Processed: brief-obscene-huge-discount.png\n",
      "Processed: bright-delicious-apathetic-distance.png\n",
      "Processed: bright-embarrassed-venomous-hair.png\n",
      "Processed: bright-oceanic-old-grab.png\n",
      "Processed: bright-wiry-silly-shelter.png\n",
      "Processed: broad-round-unbecoming-scheme.png\n",
      "Processed: broad-sweet-cooing-newspaper.png\n",
      "Processed: cagey-stereotyped-wholesale-society.png\n",
      "Processed: calculating-protective-creepy-look.png\n",
      "Processed: careless-classy-vast-chest.png\n",
      "Processed: ceaseless-ajar-lovely-estate.png\n",
      "Processed: ceaseless-unequaled-malicious-ride.png\n",
      "Processed: certain-mushy-picayune-revenue.png\n",
      "Processed: charming-defeated-voracious-beat.png\n",
      "Processed: cheap-curly-bad-river.png\n",
      "Processed: chubby-unnatural-spurious-structure.png\n",
      "Processed: clammy-lovely-demonic-guidance.png\n",
      "Processed: clear-honorable-red-command.png\n",
      "Processed: clear-real-clumsy-disk.png\n",
      "Processed: closed-secretive-icy-issue.png\n",
      "Processed: coherent-determined-sour-foot.png\n",
      "Processed: cold-gaping-undesirable-training.png\n",
      "Processed: colorful-macho-ratty-treat.png\n",
      "Processed: colorful-phobic-shocking-army.png\n",
      "Processed: common-jumbled-excited-charge.png\n",
      "Processed: common-unarmed-bustling-game.png\n",
      "Processed: condemned-separate-quiet-concept.png\n",
      "Processed: conscious-cloistered-ablaze-health.png\n",
      "Processed: cooing-soft-rotten-insurance.png\n",
      "Processed: cool-dead-whispering-present.png\n",
      "Processed: cowardly-willing-efficacious-poem.png\n",
      "Processed: crowded-stingy-disgusting-serve.png\n",
      "Processed: cultured-loud-equable-injury.png\n",
      "Processed: curved-fluttering-upbeat-energy.png\n",
      "Processed: cut-somber-exclusive-university.png\n",
      "Processed: daffy-malicious-spiky-student.png\n",
      "Processed: damaged-ratty-disgusting-square.png\n",
      "Processed: dangerous-vast-big-replacement.png\n",
      "Processed: dashing-delicious-insidious-science.png\n",
      "Processed: dashing-wide-diligent-sad.png\n",
      "Processed: deafening-boorish-imported-nothing.png\n",
      "Processed: dear-curvy-known-ease.png\n",
      "Processed: decisive-murky-windy-amount.png\n",
      "Processed: decisive-vagabond-unknown-science.png\n",
      "Processed: dependent-feigned-premium-candy.png\n",
      "Processed: dependent-hellish-hurt-diet.png\n",
      "Processed: determined-steadfast-spicy-kind.png\n",
      "Processed: devilish-unwritten-fast-wake.png\n",
      "Processed: different-glossy-smart-clock.png\n",
      "Processed: dirty-debonair-gainful-strip.png\n",
      "Processed: dirty-willing-brainy-plane.png\n",
      "Processed: disgusting-brawny-spectacular-plate.png\n",
      "Processed: dispensable-snotty-luxuriant-policy.png\n",
      "Processed: divergent-vagabond-purring-response.png\n",
      "Processed: dizzy-rampant-snobbish-setting.png\n",
      "Processed: domineering-acid-alleged-bridge.png\n",
      "Processed: dramatic-ugliest-awake-king.png\n",
      "Processed: dreary-comfortable-brawny-working.png\n",
      "Processed: dry-puzzling-six-fear.png\n",
      "Processed: dynamic-prickly-tasteless-bus.png\n",
      "Processed: eager-anxious-idiotic-topic.png\n",
      "Processed: eager-smiling-substantial-support.png\n",
      "Processed: economic-exultant-spurious-self.png\n",
      "Processed: economic-hesitant-modern-junior.png\n",
      "Processed: economic-orange-quaint-news.png\n",
      "Processed: elastic-messy-cynical-catch.png\n",
      "Processed: elated-woebegone-fretful-farm.png\n",
      "Processed: electric-steep-tenuous-north.png\n",
      "Processed: elegant-vast-ambitious-parent.png\n",
      "Processed: elite-nutty-opposite-weight.png\n",
      "Processed: enthusiastic-plain-resolute-bus.png\n",
      "Processed: envious-pumped-flat-dream.png\n",
      "Processed: exclusive-sweltering-rampant-party.png\n",
      "Processed: faint-muddled-physical-husband.png\n",
      "Processed: fair-shut-concerned-one.png\n",
      "Processed: false-muddled-windy-view.png\n",
      "Processed: fanatical-absurd-abject-cancel.png\n",
      "Processed: fascinated-incandescent-silky-sport.png\n",
      "Processed: fast-grouchy-snotty-bet.png\n",
      "Processed: fat-noxious-doubtful-walk.png\n",
      "Processed: faulty-pathetic-past-error.png\n",
      "Processed: fearful-responsible-magenta-memory.png\n",
      "Processed: feigned-separate-many-surround.png\n",
      "Processed: festive-cagey-economic-initiative.png\n",
      "Processed: fierce-aromatic-smelly-judge.png\n",
      "Processed: fixed-light-tenuous-minimum.png\n",
      "Processed: flagrant-comfortable-towering-juice.png\n",
      "Processed: flaky-premium-wasteful-god.png\n",
      "Processed: flawless-yummy-faint-occasion.png\n",
      "Processed: foolish-second-orange-note.png\n",
      "Processed: foolish-thoughtful-fluffy-distance.png\n",
      "Processed: forgetful-panoramic-bitter-blue.png\n",
      "Processed: fortunate-changeable-eatable-market.png\n",
      "Processed: four-shaggy-last-essay.png\n",
      "Processed: freezing-thankful-unequaled-shelter.png\n",
      "Processed: frequent-rainy-clean-problem.png\n",
      "Processed: fresh-tacky-inconclusive-press.png\n",
      "Processed: frightened-different-likeable-sort.png\n",
      "Processed: furry-unable-rotten-entertainment.png\n",
      "Processed: fuzzy-nifty-disastrous-bonus.png\n",
      "Processed: gainful-thinkable-boiling-piano.png\n",
      "Processed: gamy-tearful-burly-church.png\n",
      "Processed: garrulous-superb-luxuriant-tomorrow.png\n",
      "Processed: gaudy-colossal-solid-call.png\n",
      "Processed: gentle-polite-lowly-atmosphere.png\n",
      "Processed: giddy-shallow-null-raw.png\n",
      "Processed: goofy-obeisant-charming-role.png\n",
      "Processed: graceful-nutty-wonderful-nobody.png\n",
      "Processed: grandiose-forgetful-marked-initiative.png\n",
      "Processed: grateful-stingy-faded-pack.png\n",
      "Processed: gray-boundless-rapid-group.png\n",
      "Processed: greasy-heartbreaking-married-race.png\n",
      "Processed: greasy-imminent-thankful-bus.png\n",
      "Processed: greasy-possible-capable-today.png\n",
      "Processed: green-melodic-foamy-silly.png\n",
      "Processed: groovy-far-large-sector.png\n",
      "Processed: grotesque-festive-devilish-advantage.png\n",
      "Processed: gruesome-silly-illustrious-grab.png\n",
      "Processed: gruesome-spiteful-guarded-annual.png\n",
      "Processed: gullible-excited-parallel-speed.png\n",
      "Processed: guttural-xenophobic-divergent-marketing.png\n",
      "Processed: habitual-aboard-handy-officer.png\n",
      "Processed: habitual-ordinary-purring-shame.png\n",
      "Processed: half-luxuriant-handy-depth.png\n",
      "Processed: halting-abounding-vigorous-log.png\n",
      "Processed: halting-weak-free-sentence.png\n",
      "Processed: handsomely-marvelous-same-screen.png\n",
      "Processed: handsomely-wasteful-drunk-newspaper.png\n",
      "Processed: handy-second-disastrous-shopping.png\n",
      "Processed: healthy-nebulous-silent-feel.png\n",
      "Processed: heavy-disillusioned-unnatural-camp.png\n",
      "Processed: helpful-offbeat-important-introduction.png\n",
      "Processed: hesitant-curly-freezing-day.png\n",
      "Processed: hesitant-harmonious-low-nature.png\n",
      "Processed: hideous-marked-gratis-flow.png\n",
      "Processed: highfalutin-waiting-kaput-complaint.png\n",
      "Processed: hissing-mundane-waggish-fruit.png\n",
      "Processed: hissing-unused-hypnotic-list.png\n",
      "Processed: homely-humdrum-puffy-failure.png\n",
      "Processed: hot-mature-electric-blue.png\n",
      "Processed: humorous-thin-disgusted-eye.png\n",
      "Processed: hurt-spiky-stormy-special.png\n",
      "Processed: hushed-zany-dysfunctional-wall.png\n",
      "Processed: husky-rich-crooked-debt.png\n",
      "Processed: illegal-alcoholic-perfect-appeal.png\n",
      "Processed: imminent-dapper-standing-personality.png\n",
      "Processed: impossible-standing-vengeful-punch.png\n",
      "Processed: incompetent-abnormal-funny-basis.png\n",
      "Processed: inconclusive-unequal-super-clerk.png\n",
      "Processed: industrious-onerous-past-smile.png\n",
      "Processed: infamous-noisy-rare-bitter.png\n",
      "Processed: innocent-chief-spurious-television.png\n",
      "Processed: inquisitive-hellish-roomy-display.png\n",
      "Processed: inquisitive-intelligent-miscreant-part.png\n",
      "Processed: irritating-statuesque-poor-tooth.png\n",
      "Processed: irritating-uninterested-uneven-driver.png\n",
      "Processed: jazzy-spotty-fresh-bottom.png\n",
      "Processed: jealous-guttural-aloof-spend.png\n",
      "Processed: jealous-undesirable-jazzy-necessary.png\n",
      "Processed: jobless-safe-spiky-chocolate.png\n",
      "Processed: juicy-equal-rural-rock.png\n",
      "Processed: juicy-ugliest-scrawny-delay.png\n",
      "Processed: juvenile-waiting-adorable-mall.png\n",
      "Processed: kaput-foamy-nippy-charge.png\n",
      "Processed: kaput-unhealthy-rigid-system.png\n",
      "Processed: kind-flippant-scary-friend.png\n",
      "Processed: known-disturbed-curved-schedule.png\n",
      "Processed: known-flaky-crowded-lift.png\n",
      "Processed: known-present-holistic-care.png\n",
      "Processed: lacking-nasty-fertile-country.png\n",
      "Processed: lame-exciting-scattered-request.png\n",
      "Processed: lamentable-eminent-miscreant-arm.png\n",
      "Processed: learned-selfish-elfin-growth.png\n",
      "Processed: legal-aspiring-sturdy-air.png\n",
      "Processed: lethal-tense-voiceless-resort.png\n",
      "Processed: like-overt-fantastic-profile.png\n",
      "Processed: like-ready-clean-bathroom.png\n",
      "Processed: likeable-innate-judicious-can.png\n",
      "Processed: lively-agreeable-devilish-budget.png\n",
      "Processed: lively-familiar-cheap-progress.png\n",
      "Processed: lively-smart-efficient-ask.png\n",
      "Processed: living-solid-ritzy-file.png\n",
      "Processed: lonely-colossal-creepy-mobile.png\n",
      "Processed: lopsided-actually-squealing-swim.png\n",
      "Processed: low-silky-happy-double.png\n",
      "Processed: luxuriant-naughty-red-football.png\n",
      "Processed: magnificent-demonic-faint-recommendation.png\n",
      "Processed: majestic-labored-better-pop.png\n",
      "Processed: maniacal-skinny-ordinary-suggestion.png\n",
      "Processed: married-imminent-sticky-following.png\n",
      "Processed: materialistic-pushy-chemical-possible.png\n",
      "Processed: mean-rightful-helpless-park.png\n",
      "Processed: meaty-puzzled-tangy-touch.png\n",
      "Processed: medical-yielding-highfalutin-tourist.png\n",
      "Processed: meek-opposite-dysfunctional-implement.png\n",
      "Processed: melodic-marvelous-eatable-calendar.png\n",
      "Processed: melodic-organic-obsequious-stranger.png\n",
      "Processed: merciful-crabby-cultured-brush.png\n",
      "Processed: mere-husky-loutish-bread.png\n",
      "Processed: mere-rich-youthful-training.png\n",
      "Processed: mere-small-cute-wing.png\n",
      "Processed: messy-soggy-purring-tomorrow.png\n",
      "Processed: minor-amazing-overjoyed-nurse.png\n",
      "Processed: mixed-painful-wonderful-youth.png\n",
      "Processed: moldy-melted-enchanting-use.png\n",
      "Processed: mountainous-bawdy-swift-grandfather.png\n",
      "Processed: muddled-nice-hanging-piano.png\n",
      "Processed: mundane-joyous-rough-confusion.png\n",
      "Processed: murky-grateful-wacky-vacation.png\n",
      "Processed: murky-wiggly-shy-piece.png\n",
      "Processed: naughty-numberless-wasteful-responsibility.png\n",
      "Processed: nauseating-workable-windy-sink.png\n",
      "Processed: neat-alcoholic-raspy-interest.png\n",
      "Processed: neat-fierce-stupendous-strain.png\n",
      "Processed: nebulous-left-dashing-dimension.png\n",
      "Processed: neighborly-political-stupid-due.png\n",
      "Processed: nervous-past-unbiased-date.png\n",
      "Processed: nice-plucky-blue-stick.png\n",
      "Processed: nippy-succinct-feigned-letter.png\n",
      "Processed: normal-adorable-annoyed-election.png\n",
      "Processed: nostalgic-two-silly-support.png\n",
      "Processed: null-hungry-wry-success.png\n",
      "Processed: numerous-misty-meek-today.png\n",
      "Processed: numerous-sticky-earthy-evidence.png\n",
      "Processed: nutritious-incandescent-workable-handle.png\n",
      "Processed: observant-plucky-lumpy-garage.png\n",
      "Processed: obtainable-squeamish-demonic-protection.png\n",
      "Processed: old-wet-evasive-influence.png\n",
      "Processed: one-naive-filthy-membership.png\n",
      "Processed: onerous-bent-voracious-ambition.png\n",
      "Processed: onerous-curly-stereotyped-bathroom.png\n",
      "Processed: onerous-shut-early-membership.png\n",
      "Processed: open-handsomely-clean-fun.png\n",
      "Processed: optimal-old-hurried-cigarette.png\n",
      "Processed: orange-lyrical-gaudy-energy.png\n",
      "Processed: ordinary-blushing-useful-glove.png\n",
      "Processed: ossified-adamant-thinkable-window.png\n",
      "Processed: ossified-puffy-fortunate-specialist.png\n",
      "Processed: outgoing-irate-uptight-rub.png\n",
      "Processed: overjoyed-aberrant-cluttered-shine.png\n",
      "Processed: overwrought-tense-ill-possession.png\n",
      "Processed: painstaking-picayune-tense-preference.png\n",
      "Processed: pale-dead-sweltering-value.png\n",
      "Processed: panicky-imperfect-breezy-suspect.png\n",
      "Processed: parallel-pastoral-helpful-alcohol.png\n",
      "Processed: parallel-stale-rainy-equipment.png\n",
      "Processed: parched-cruel-silly-collar.png\n",
      "Processed: parsimonious-rabid-productive-building.png\n",
      "Processed: past-noiseless-accurate-stranger.png\n",
      "Processed: pathetic-worthless-penitent-war.png\n",
      "Processed: perpetual-long-hissing-position.png\n",
      "Processed: perpetual-magenta-naive-security.png\n",
      "Processed: perpetual-overjoyed-unruly-minute.png\n",
      "Processed: physical-ruthless-fat-anybody.png\n",
      "Processed: piquant-subsequent-dusty-make.png\n",
      "Processed: placid-abhorrent-excited-entertainment.png\n",
      "Processed: pleasant-far-hurt-blind.png\n",
      "Processed: plucky-secret-dusty-window.png\n",
      "Processed: pointless-eight-vulgar-increase.png\n",
      "Processed: possessive-eager-great-priest.png\n",
      "Processed: precious-unsightly-adaptable-truth.png\n",
      "Processed: previous-dusty-shut-teach.png\n",
      "Processed: pricey-spicy-important-cream.png\n",
      "Processed: prickly-historical-tedious-perception.png\n",
      "Processed: probable-necessary-grandiose-purpose.png\n",
      "Processed: profuse-telling-xenophobic-interaction.png\n",
      "Processed: protective-busy-rude-depression.png\n",
      "Processed: psychedelic-observant-unsightly-inspector.png\n",
      "Processed: psychotic-mixed-obsequious-arm.png\n",
      "Processed: psychotic-odd-slimy-member.png\n",
      "Processed: psychotic-thoughtful-equable-brush.png\n",
      "Processed: puny-sour-foolish-active.png\n",
      "Processed: quiet-insidious-nauseating-sense.png\n",
      "Processed: racial-tan-wanting-steak.png\n",
      "Processed: receptive-humdrum-ratty-competition.png\n",
      "Processed: red-eight-chubby-mix.png\n",
      "Processed: red-free-overrated-sail.png\n",
      "Processed: regular-whole-square-boy.png\n",
      "Processed: rich-endurable-many-ask.png\n",
      "Processed: right-impartial-spicy-oil.png\n",
      "Processed: righteous-super-proud-big.png\n",
      "Processed: robust-drunk-rampant-trouble.png\n",
      "Processed: rotten-feigned-oceanic-breast.png\n",
      "Processed: rotten-young-decorous-object.png\n",
      "Processed: ruddy-flagrant-tedious-trouble.png\n",
      "Processed: rustic-lovely-zesty-spare.png\n",
      "Processed: ruthless-worried-earthy-conflict.png\n",
      "Processed: sable-entertaining-friendly-stupid.png\n",
      "Processed: savory-highfalutin-slimy-control.png\n",
      "Processed: scarce-aloof-different-stage.png\n",
      "Processed: scarce-nervous-acrid-awareness.png\n",
      "Processed: scary-homely-successful-matter.png\n",
      "Processed: sedate-adorable-general-milk.png\n",
      "Processed: seemly-nine-pastoral-a.png\n",
      "Processed: sharp-futuristic-utopian-math.png\n",
      "Processed: shrill-internal-hurried-chain.png\n",
      "Processed: simplistic-nondescript-naughty-campaign.png\n",
      "Processed: six-cluttered-holistic-guide.png\n",
      "Processed: skinny-mundane-rampant-record.png\n",
      "Processed: skinny-slow-available-post.png\n",
      "Processed: sleepy-true-ten-supermarket.png\n",
      "Processed: slippery-bloody-tasty-wear.png\n",
      "Processed: small-sparkling-cloistered-library.png\n",
      "Processed: smiling-dusty-beneficial-shoulder.png\n",
      "Processed: sneaky-delicate-grumpy-character.png\n",
      "Processed: soft-gullible-famous-post.png\n",
      "Processed: solid-statuesque-like-recommendation.png\n",
      "Processed: sore-nine-condemned-system.png\n",
      "Processed: sour-curved-vivacious-egg.png\n",
      "Processed: spectacular-elastic-rabid-grade.png\n",
      "Processed: spiffy-succinct-lean-pay.png\n",
      "Processed: spiffy-versed-irritating-extreme.png\n",
      "Processed: spiteful-aback-ahead-alternative.png\n",
      "Processed: spotless-determined-excellent-talk.png\n",
      "Processed: spotless-ill-talented-farm.png\n",
      "Processed: squealing-versed-stormy-senior.png\n",
      "Processed: squeamish-offbeat-new-goal.png\n",
      "Processed: statuesque-furry-damaged-two.png\n",
      "Processed: statuesque-resonant-heartbreaking-weekend.png\n",
      "Processed: steadfast-gaping-screeching-chicken.png\n",
      "Processed: steady-mushy-lumpy-pension.png\n",
      "Processed: stimulating-gratis-pointless-snow.png\n",
      "Processed: stingy-deep-demonic-baseball.png\n",
      "Processed: stingy-versed-kindly-client.png\n",
      "Processed: striped-phobic-decisive-examination.png\n",
      "Processed: striped-ultra-repulsive-spare.png\n",
      "Processed: stupendous-decorous-shiny-mirror.png\n",
      "Processed: stupendous-picayune-coherent-quiet.png\n",
      "Processed: stupid-abaft-white-quality.png\n",
      "Processed: subdued-glorious-somber-policy.png\n",
      "Processed: subsequent-wooden-tasty-neat.png\n",
      "Processed: substantial-quack-lumpy-media.png\n",
      "Processed: substantial-responsible-needy-article.png\n",
      "Processed: substantial-weary-materialistic-pollution.png\n",
      "Processed: successful-irate-honorable-mobile.png\n",
      "Processed: successful-unequal-inexpensive-bit.png\n",
      "Processed: succinct-impossible-tedious-target.png\n",
      "Processed: superb-willing-functional-flight.png\n",
      "Processed: supreme-direful-cautious-agent.png\n",
      "Processed: swanky-useless-eminent-charge.png\n",
      "Processed: tangible-thankful-adaptable-sea.png\n",
      "Processed: tangy-earsplitting-uneven-leave.png\n",
      "Processed: tangy-previous-ill-drawing.png\n",
      "Processed: tasteful-creepy-coherent-language.png\n",
      "Processed: tasty-superficial-lively-child.png\n",
      "Processed: tawdry-aware-wiggly-definition.png\n",
      "Processed: tawdry-disgusting-furtive-performance.png\n",
      "Processed: ten-diligent-fertile-past.png\n",
      "Processed: tense-majestic-acceptable-goal.png\n",
      "Processed: therapeutic-tender-fair-map.png\n",
      "Processed: thick-sweet-sparkling-estate.png\n",
      "Processed: thin-famous-greasy-produce.png\n",
      "Processed: thin-huge-scandalous-relation.png\n",
      "Processed: thinkable-nervous-private-recording.png\n",
      "Processed: thinkable-omniscient-necessary-status.png\n",
      "Processed: third-bewildered-smiling-north.png\n",
      "Processed: third-jumpy-bent-space.png\n",
      "Processed: third-quixotic-useless-student.png\n",
      "Processed: thirsty-cheap-plant-award.png\n",
      "Processed: thoughtful-waggish-incandescent-sign.png\n",
      "Processed: thoughtless-adhesive-calm-setting.png\n",
      "Processed: three-plucky-wandering-thought.png\n",
      "Processed: tired-abject-ludicrous-machine.png\n",
      "Processed: tiresome-green-smelly-question.png\n",
      "Processed: toothsome-stingy-few-press.png\n",
      "Processed: towering-meaty-nappy-entertainment.png\n",
      "Processed: tranquil-afraid-changeable-post.png\n",
      "Processed: tranquil-mere-pushy-snow.png\n",
      "Processed: tremendous-wonderful-odd-shift.png\n",
      "Processed: tricky-sturdy-impossible-sweet.png\n",
      "Processed: trite-chief-noxious-ratio.png\n",
      "Processed: troubled-cooperative-whole-hunt.png\n",
      "Processed: truthful-lively-illustrious-local.png\n",
      "Processed: typical-one-crabby-moment.png\n",
      "Processed: ugliest-ugly-yummy-routine.png\n",
      "Processed: ugly-squeamish-illustrious-temperature.png\n",
      "Processed: unequal-tasteful-discreet-shift.png\n",
      "Processed: uninterested-ignorant-smelly-pin.png\n",
      "Processed: unkempt-nutty-male-platform.png\n",
      "Processed: unruly-material-historical-context.png\n",
      "Processed: unsightly-quaint-good-surround.png\n",
      "Processed: unsuitable-feigned-harmonious-read.png\n",
      "Processed: untidy-elderly-strange-end.png\n",
      "Processed: utter-harsh-safe-designer.png\n",
      "Processed: vacuous-vigorous-cheap-movie.png\n",
      "Processed: vague-outstanding-wrong-while.png\n",
      "Processed: various-abundant-moaning-cross.png\n",
      "Processed: vengeful-hollow-male-writer.png\n",
      "Processed: vengeful-ludicrous-tired-march.png\n",
      "Processed: vengeful-rhetorical-outgoing-judge.png\n",
      "Processed: venomous-agreeable-half-wonder.png\n",
      "Processed: verdant-lumpy-lumpy-steal.png\n",
      "Processed: voiceless-ambitious-sour-standard.png\n",
      "Processed: wacky-quixotic-thirsty-combine.png\n",
      "Processed: wanting-functional-goofy-possible.png\n",
      "Processed: warlike-furtive-unbiased-pound.png\n",
      "Processed: wicked-simplistic-dreary-lock.png\n",
      "Processed: willing-grandiose-testy-zone.png\n",
      "Processed: windy-sad-nine-touch.png\n",
      "Processed: wiry-sudden-energetic-assignment.png\n",
      "Processed: wistful-few-hushed-horse.png\n",
      "Processed: wistful-rustic-interesting-memory.png\n",
      "Processed: womanly-fluttering-milky-row.png\n",
      "Processed: wooden-permissible-fertile-inside.png\n",
      "Processed: woozy-waiting-aspiring-sex.png\n",
      "Processed: worthless-boundless-voracious-aspect.png\n",
      "Processed: wrathful-lyrical-alcoholic-county.png\n",
      "Processed: wrathful-plant-majestic-perception.png\n",
      "Processed: youthful-smiling-abrasive-lab.png\n",
      "Processed: yummy-neat-frantic-sound.png\n",
      "Processed: zany-cloudy-true-part.png\n",
      "Processed: zealous-parsimonious-smiling-fun.png\n",
      "Processed: zippy-piquant-fascinated-bag.png\n",
      "Processed: zonked-silent-snobbish-review.png\n",
      "OCR completed. Extracted text saved to /Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/extracted_texts.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory containing PNG files and the output CSV file\n",
    "image_dir = \"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/Clean_phishing\"  \n",
    "output_csv = \"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/extracted_texts.csv\" \n",
    "\n",
    "# List to store extracted text data\n",
    "data = []\n",
    "\n",
    "# Process each PNG file in the directory\n",
    "for file_name in os.listdir(image_dir):\n",
    "    if file_name.lower().endswith(\".png\"):\n",
    "        image_path = os.path.join(image_dir, file_name)\n",
    "        try:\n",
    "            # Open the image and extract text using OCR\n",
    "            text = pytesseract.image_to_string(Image.open(image_path))\n",
    "            # Append the filename and extracted text to the list\n",
    "            data.append({\"file_name\": file_name, \"extracted_text\": text})\n",
    "            print(f\"Processed: {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n",
    "\n",
    "# Convert the data list to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"OCR completed. Extracted text saved to {output_csv}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame saved to /Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/extracted_texts_with_brands.csv.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the ground_truth_visjs.json file\n",
    "json_file_path = \"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/ground_truth_visjs.json\"  \n",
    "with open(json_file_path, \"r\") as file:\n",
    "    clusters = json.load(file)\n",
    "\n",
    "# Create a mapping of file names to their corresponding cluster (brand)\n",
    "file_to_cluster = {}\n",
    "for cluster_data in clusters:\n",
    "    cluster_name = cluster_data[\"cluster\"]\n",
    "    members = cluster_data[\"members\"]\n",
    "    for file_name in members:\n",
    "        file_to_cluster[file_name] = cluster_name\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "csv_file_path = \"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/extracted_texts.csv\" \n",
    "#df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Map the \"brand\" based on the file_to_cluster dictionary\n",
    "df[\"brand\"] = df[\"file_name\"].map(file_to_cluster)\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file\n",
    "output_csv_path = \"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/extracted_texts_with_brands.csv\"  \n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Updated DataFrame saved to {output_csv_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand\n",
       "uncomplete         64\n",
       "unloaded           42\n",
       "N26                39\n",
       "microsoft          36\n",
       "errorMessage       25\n",
       "CounterStrike      22\n",
       "misc               19\n",
       "Advanzia           17\n",
       "CirclWebServer     15\n",
       "ackouperm          13\n",
       "BancoInter         12\n",
       "Office             11\n",
       "Steam              11\n",
       "TaggingServer      11\n",
       "Outlook            11\n",
       "formular           10\n",
       "Oldcircl            9\n",
       "SPankki             8\n",
       "KBC                 7\n",
       "WeTransfer          6\n",
       "news                6\n",
       "fibank              5\n",
       "EmiratesNBD         5\n",
       "OrangeWebmail       5\n",
       "paypal              5\n",
       "OneDrive            4\n",
       "multilogo           4\n",
       "CarreBlue           3\n",
       "ForeignLanguage     3\n",
       "Windows             3\n",
       "google              3\n",
       "rackspace           3\n",
       "dhl                 2\n",
       "bitcoin             2\n",
       "Post                2\n",
       "hsbc                2\n",
       "Netflix             2\n",
       "FrImpots            2\n",
       "WellsFargo          2\n",
       "DropBox             2\n",
       "android             2\n",
       "AmericanExpress     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['brand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ablaze-jazzy-tangy-file.png</td>\n",
       "      <td>ol Confirm you r account circl lu password j...</td>\n",
       "      <td>CirclWebServer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aggressive-defiant-imminent-bottle.png</td>\n",
       "      <td>4  m ad Confirm your account taggingserver com...</td>\n",
       "      <td>CirclWebServer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>dispensable-snotty-luxuriant-policy.png</td>\n",
       "      <td>ol Confirm you r account circl lu password j...</td>\n",
       "      <td>CirclWebServer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>halting-abounding-vigorous-log.png</td>\n",
       "      <td>4  m ad Confirm your account taggingserver com...</td>\n",
       "      <td>CirclWebServer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>kaput-foamy-nippy-charge.png</td>\n",
       "      <td>ol Confirm you r account circl lu password j...</td>\n",
       "      <td>CirclWebServer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   file_name  \\\n",
       "1                ablaze-jazzy-tangy-file.png   \n",
       "16    aggressive-defiant-imminent-bottle.png   \n",
       "95   dispensable-snotty-luxuriant-policy.png   \n",
       "167       halting-abounding-vigorous-log.png   \n",
       "206             kaput-foamy-nippy-charge.png   \n",
       "\n",
       "                                        extracted_text           brand  \n",
       "1      ol Confirm you r account circl lu password j...  CirclWebServer  \n",
       "16   4  m ad Confirm your account taggingserver com...  CirclWebServer  \n",
       "95     ol Confirm you r account circl lu password j...  CirclWebServer  \n",
       "167  4  m ad Confirm your account taggingserver com...  CirclWebServer  \n",
       "206    ol Confirm you r account circl lu password j...  CirclWebServer  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show brand = android\n",
    "df[df['brand']=='CirclWebServer'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textual Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame saved to /Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/extracted_texts_cleaned.csv.\n"
     ]
    }
   ],
   "source": [
    "# Remove newlines, tabs, and excessive spaces\n",
    "\n",
    "import re\n",
    "\n",
    "# Function to clean extracted text\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Remove newlines, tabs, and excessive spaces\n",
    "        text = re.sub(r'\\s+', ' ', text.strip())  # Replace multiple spaces/newlines with a single space\n",
    "        text = re.sub(r'[^\\x20-\\x7E]', '', text)  # Remove non-ASCII characters (optional)\n",
    "        text = text.replace(\"\\n\", \" \").replace(\"\\t\", \" \").replace(\"\\r\", \" \").replace(\"@\", \" \").replace(\":\", \" \").replace(\";\", \" \").replace(\"!\", \" \").replace(\"#\", \" \").replace(\"$\", \" \").replace(\"%\", \" \").replace(\"^\", \" \").replace(\"&\", \" \").replace(\"*\", \" \").replace(\"(\", \" \").replace(\")\", \" \").replace(\"-\", \" \").replace(\"_\", \" \").replace(\"+\", \" \").replace(\"=\", \" \").replace(\"{\", \" \").replace(\"}\", \" \").replace(\"[\", \" \").replace(\"]\", \" \").replace(\"|\", \" \").replace(\"\\\\\", \" \").replace(\":\", \" \").replace(\"\\\"\", \" \").replace(\"'\", \" \").replace(\"<\", \" \").replace(\">\", \" \").replace(\",\", \" \").replace(\".\", \" \").replace(\"?\", \" \").replace(\"/\", \" \")\n",
    "    return text\n",
    "\n",
    "# Apply cleaning to the 'extracted_text' column\n",
    "df['extracted_text'] = df['extracted_text'].apply(clean_text)\n",
    "\n",
    "# Save the cleaned DataFrame back to the file\n",
    "cleaned_csv_path = \"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/extracted_texts_cleaned.csv\"  # Update the path as needed\n",
    "df.to_csv(cleaned_csv_path, index=False)\n",
    "\n",
    "print(f\"Cleaned DataFrame saved to {cleaned_csv_path}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features (visual + textual) via CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbee7e0a6d9e45d38da85935496c707b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6de90fd1504346b25c8b365299115c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c70feaf8734d8bac61cde02050bd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bbfa8a8e034d8397cd47dc9ab2739a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e94ae4efb664fbabb398ef61abc73e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee5e8f273c448329c22e779248fc97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61a3becfbc94a5b8a99c1156fc1d04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f2bb7b9a3049608bb31ffd93cb0b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to /Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/embeddings.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# Initialize the CLIP model and processor\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Paths and data\n",
    "image_dir = \"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/Clean_phishing\"\n",
    "\n",
    "# Function to get image embeddings\n",
    "def get_image_embedding(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        image_features = model.get_image_features(**inputs)\n",
    "        return image_features.detach().cpu().numpy().flatten()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to get text embeddings\n",
    "def get_text_embedding(text):\n",
    "    try:\n",
    "        inputs = processor(text=text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        text_features = model.get_text_features(**inputs)\n",
    "        return text_features.detach().cpu().numpy().flatten()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return None\n",
    "\n",
    "# Add columns for image and text embeddings to the DataFrame\n",
    "image_embeddings = []\n",
    "text_embeddings = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    image_path = os.path.join(image_dir, row[\"file_name\"])\n",
    "    text = row[\"extracted_text\"]\n",
    "    \n",
    "    # Extract image and text embeddings\n",
    "    img_emb = get_image_embedding(image_path)\n",
    "    text_emb = get_text_embedding(text)\n",
    "    \n",
    "    image_embeddings.append(img_emb)\n",
    "    text_embeddings.append(text_emb)\n",
    "\n",
    "# Add embeddings to the DataFrame\n",
    "df[\"image_embedding\"] = image_embeddings\n",
    "df[\"text_embedding\"] = text_embeddings\n",
    "\n",
    "# Save embeddings to a file\n",
    "output_csv_path = \"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/embeddings.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Embeddings saved to {output_csv_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>brand</th>\n",
       "      <th>image_embedding</th>\n",
       "      <th>text_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abashed-careless-ordinary-crew.png</td>\n",
       "      <td>N26 Actualiser les GmbH   paramtres des 2019 c...</td>\n",
       "      <td>unloaded</td>\n",
       "      <td>[-0.14099549, 0.18997173, 0.12000446, 0.205960...</td>\n",
       "      <td>[0.14271626, -0.23965064, -0.17083012, 0.11320...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ablaze-jazzy-tangy-file.png</td>\n",
       "      <td>ol Confirm you r account circl lu password j...</td>\n",
       "      <td>CirclWebServer</td>\n",
       "      <td>[0.14484096, 0.26118287, -0.1034108, 0.1293356...</td>\n",
       "      <td>[0.27832943, 0.19564445, -0.30090627, 0.206732...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ablaze-lean-grubby-particular.png</td>\n",
       "      <td>IT Mobiles Entertainment Wissen Netzpolitik Wi...</td>\n",
       "      <td>unloaded</td>\n",
       "      <td>[-0.12322151, 0.30594707, -0.007408384, 0.1513...</td>\n",
       "      <td>[-0.10782848, 0.34986025, -0.30775118, 0.02452...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>able-yellow-defective-variety.png</td>\n",
       "      <td>EE Microsoft Pick an account undefined b use a...</td>\n",
       "      <td>unloaded</td>\n",
       "      <td>[-0.021512665, 0.0829493, -0.056524467, 0.3748...</td>\n",
       "      <td>[0.20450851, 0.18280731, -0.23862273, 0.319023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abstracted-colossal-rich-race.png</td>\n",
       "      <td>Transaktionen oo Spaces a Mein Konto   N26 Bit...</td>\n",
       "      <td>N26</td>\n",
       "      <td>[-0.09904538, 0.17214404, 0.0125989895, 0.0279...</td>\n",
       "      <td>[0.049980957, -0.027177861, 0.19742016, 0.1905...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>yummy-neat-frantic-sound.png</td>\n",
       "      <td>Need login a  B  a         a a a a i</td>\n",
       "      <td>CounterStrike</td>\n",
       "      <td>[0.07600027, -0.31320873, 0.0018638405, -0.302...</td>\n",
       "      <td>[0.13922371, 0.103531815, 0.048435986, -0.0286...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>zany-cloudy-true-part.png</td>\n",
       "      <td>Microsoft Taking you to your organization s si...</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>[-0.3799956, 0.39194575, -0.24593008, 0.250652...</td>\n",
       "      <td>[0.052628953, 0.23422095, -0.5313105, 0.151695...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>zealous-parsimonious-smiling-fun.png</td>\n",
       "      <td>Microsoft Enter passw D2018 Microsoft Terms of...</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>[0.3621599, -0.06515593, -0.21567273, 0.071415...</td>\n",
       "      <td>[0.007452556, -0.066111065, -0.3963314, 0.1852...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>zippy-piquant-fascinated-bag.png</td>\n",
       "      <td>1 Office 365 Verify your email password to con...</td>\n",
       "      <td>Office</td>\n",
       "      <td>[-0.00078154635, -0.015230171, 0.14547199, -0....</td>\n",
       "      <td>[0.208157, -0.48072356, -0.6584283, 0.08933899...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>zonked-silent-snobbish-review.png</td>\n",
       "      <td>Confirm your ID to upgrade your Email Account ...</td>\n",
       "      <td>Oldcircl</td>\n",
       "      <td>[0.18495777, 0.13453835, -0.10080049, 0.134470...</td>\n",
       "      <td>[0.21888481, 0.091272056, -0.141533, 0.0817469...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>457 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                file_name  \\\n",
       "0      abashed-careless-ordinary-crew.png   \n",
       "1             ablaze-jazzy-tangy-file.png   \n",
       "2       ablaze-lean-grubby-particular.png   \n",
       "3       able-yellow-defective-variety.png   \n",
       "4       abstracted-colossal-rich-race.png   \n",
       "..                                    ...   \n",
       "452          yummy-neat-frantic-sound.png   \n",
       "453             zany-cloudy-true-part.png   \n",
       "454  zealous-parsimonious-smiling-fun.png   \n",
       "455      zippy-piquant-fascinated-bag.png   \n",
       "456     zonked-silent-snobbish-review.png   \n",
       "\n",
       "                                        extracted_text           brand  \\\n",
       "0    N26 Actualiser les GmbH   paramtres des 2019 c...        unloaded   \n",
       "1      ol Confirm you r account circl lu password j...  CirclWebServer   \n",
       "2    IT Mobiles Entertainment Wissen Netzpolitik Wi...        unloaded   \n",
       "3    EE Microsoft Pick an account undefined b use a...        unloaded   \n",
       "4    Transaktionen oo Spaces a Mein Konto   N26 Bit...             N26   \n",
       "..                                                 ...             ...   \n",
       "452               Need login a  B  a         a a a a i   CounterStrike   \n",
       "453  Microsoft Taking you to your organization s si...       microsoft   \n",
       "454  Microsoft Enter passw D2018 Microsoft Terms of...       microsoft   \n",
       "455  1 Office 365 Verify your email password to con...          Office   \n",
       "456  Confirm your ID to upgrade your Email Account ...        Oldcircl   \n",
       "\n",
       "                                       image_embedding  \\\n",
       "0    [-0.14099549, 0.18997173, 0.12000446, 0.205960...   \n",
       "1    [0.14484096, 0.26118287, -0.1034108, 0.1293356...   \n",
       "2    [-0.12322151, 0.30594707, -0.007408384, 0.1513...   \n",
       "3    [-0.021512665, 0.0829493, -0.056524467, 0.3748...   \n",
       "4    [-0.09904538, 0.17214404, 0.0125989895, 0.0279...   \n",
       "..                                                 ...   \n",
       "452  [0.07600027, -0.31320873, 0.0018638405, -0.302...   \n",
       "453  [-0.3799956, 0.39194575, -0.24593008, 0.250652...   \n",
       "454  [0.3621599, -0.06515593, -0.21567273, 0.071415...   \n",
       "455  [-0.00078154635, -0.015230171, 0.14547199, -0....   \n",
       "456  [0.18495777, 0.13453835, -0.10080049, 0.134470...   \n",
       "\n",
       "                                        text_embedding  \n",
       "0    [0.14271626, -0.23965064, -0.17083012, 0.11320...  \n",
       "1    [0.27832943, 0.19564445, -0.30090627, 0.206732...  \n",
       "2    [-0.10782848, 0.34986025, -0.30775118, 0.02452...  \n",
       "3    [0.20450851, 0.18280731, -0.23862273, 0.319023...  \n",
       "4    [0.049980957, -0.027177861, 0.19742016, 0.1905...  \n",
       "..                                                 ...  \n",
       "452  [0.13922371, 0.103531815, 0.048435986, -0.0286...  \n",
       "453  [0.052628953, 0.23422095, -0.5313105, 0.151695...  \n",
       "454  [0.007452556, -0.066111065, -0.3963314, 0.1852...  \n",
       "455  [0.208157, -0.48072356, -0.6584283, 0.08933899...  \n",
       "456  [0.21888481, 0.091272056, -0.141533, 0.0817469...  \n",
       "\n",
       "[457 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier \n",
    "(Evaluation Metrics: Accuracy, F1, Precsion, and Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autogluon with multimodal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241208_000036\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.4.0: Wed Feb 21 21:44:06 PST 2024; root:xnu-10063.101.15~2/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.70 GB / 16.00 GB (23.2%)\n",
      "Disk Space Avail:   112.74 GB / 931.48 GB (12.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Volumes/T7/DLCOURSEWORK/AutogluonModels/ag-20241208_000036\"\n",
      "Train Data Rows:    366\n",
      "Train Data Columns: 1024\n",
      "Label Column:       brand\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 42) unique label values:  ['KBC', 'formular', 'Outlook', 'misc', 'N26', 'unloaded', 'Office', 'TaggingServer', 'errorMessage', 'uncomplete']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 2 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 2 examples. AutoGluon will only keep 39 out of 42 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 2 examples that will be kept for training models: 0.9918032786885246\n",
      "Train Data Class Count: 39\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3783.09 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.42 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1024 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1024 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\t0.7s = Fit runtime\n",
      "\t1024 features in original data used to generate 1024 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.42 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.92s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 290, Val Rows: 73\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.6575\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.6986\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 8: early stopping\n",
      "\t0.7808\t = Validation score   (accuracy)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.7808\t = Validation score   (accuracy)\n",
      "\t7.61s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.6986\t = Validation score   (accuracy)\n",
      "\t11.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7534\t = Validation score   (accuracy)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7808\t = Validation score   (accuracy)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tMany features detected (1024), dynamically setting 'colsample_bylevel' to 0.9765625 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\t0.6986\t = Validation score   (accuracy)\n",
      "\t302.06s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7397\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.726\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.7534\t = Validation score   (accuracy)\n",
      "\t21.92s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.7534\t = Validation score   (accuracy)\n",
      "\t1.51s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.6575\t = Validation score   (accuracy)\n",
      "\t64.51s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 1.0}\n",
      "\t0.7808\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 414.01s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 9423.4 rows/s (73 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Volumes/T7/DLCOURSEWORK/AutogluonModels/ag-20241208_000036\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaderboard of Models:\n",
      "                  model  score_test  score_val eval_metric  pred_time_test  \\\n",
      "0       NeuralNetFastAI    0.725275   0.780822    accuracy        0.014237   \n",
      "1   WeightedEnsemble_L2    0.725275   0.780822    accuracy        0.022228   \n",
      "2        ExtraTreesGini    0.714286   0.739726    accuracy        0.056415   \n",
      "3              CatBoost    0.703297   0.698630    accuracy        0.034480   \n",
      "4        ExtraTreesEntr    0.692308   0.726027    accuracy        0.061946   \n",
      "5        NeuralNetTorch    0.681319   0.753425    accuracy        0.016790   \n",
      "6        KNeighborsDist    0.681319   0.698630    accuracy        0.020085   \n",
      "7      RandomForestEntr    0.681319   0.780822    accuracy        0.058026   \n",
      "8      RandomForestGini    0.681319   0.753425    accuracy        0.059188   \n",
      "9            LightGBMXT    0.670330   0.780822    accuracy        0.020411   \n",
      "10       KNeighborsUnif    0.659341   0.657534    accuracy        0.012002   \n",
      "11              XGBoost    0.637363   0.753425    accuracy        0.160778   \n",
      "12             LightGBM    0.626374   0.698630    accuracy        0.021735   \n",
      "13        LightGBMLarge    0.615385   0.657534    accuracy        0.104054   \n",
      "\n",
      "    pred_time_val    fit_time  pred_time_test_marginal  \\\n",
      "0        0.007276    0.697815                 0.014237   \n",
      "1        0.007747    0.747339                 0.007991   \n",
      "2        0.031878    0.532852                 0.056415   \n",
      "3        0.014000  302.061730                 0.034480   \n",
      "4        0.030029    0.471388                 0.061946   \n",
      "5        0.008405    1.507396                 0.016790   \n",
      "6        0.006956    0.052887                 0.020085   \n",
      "7        0.026129    0.669556                 0.058026   \n",
      "8        0.023520    0.699978                 0.059188   \n",
      "9        0.005462    7.612406                 0.020411   \n",
      "10       0.006855    0.047224                 0.012002   \n",
      "11       0.005071   21.922258                 0.160778   \n",
      "12       0.005452   11.018786                 0.021735   \n",
      "13       0.023972   64.512329                 0.104054   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.007276           0.697815            1       True   \n",
      "1                 0.000471           0.049524            2       True   \n",
      "2                 0.031878           0.532852            1       True   \n",
      "3                 0.014000         302.061730            1       True   \n",
      "4                 0.030029           0.471388            1       True   \n",
      "5                 0.008405           1.507396            1       True   \n",
      "6                 0.006956           0.052887            1       True   \n",
      "7                 0.026129           0.669556            1       True   \n",
      "8                 0.023520           0.699978            1       True   \n",
      "9                 0.005462           7.612406            1       True   \n",
      "10                0.006855           0.047224            1       True   \n",
      "11                0.005071          21.922258            1       True   \n",
      "12                0.005452          11.018786            1       True   \n",
      "13                0.023972          64.512329            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0           3  \n",
      "1          14  \n",
      "2           9  \n",
      "3           8  \n",
      "4          10  \n",
      "5          12  \n",
      "6           2  \n",
      "7           7  \n",
      "8           6  \n",
      "9           4  \n",
      "10          1  \n",
      "11         11  \n",
      "12          5  \n",
      "13         13  \n",
      "\n",
      "Evaluating Model: NeuralNetFastAI\n",
      "Accuracy: 0.7253\n",
      "Precision: 0.6862\n",
      "Recall: 0.7253\n",
      "F1 Score: 0.6935\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       0.75      1.00      0.86         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       0.67      1.00      0.80         2\n",
      " CounterStrike       0.71      1.00      0.83         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.83      0.77      0.80        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.25      1.00      0.40         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "       SPankki       0.25      1.00      0.40         1\n",
      "         Steam       1.00      1.00      1.00         3\n",
      "    WeTransfer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.80      0.80      0.80         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.91      1.00      0.95        10\n",
      "          misc       0.33      0.33      0.33         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.87      1.00      0.93        13\n",
      "      unloaded       0.40      0.22      0.29         9\n",
      "\n",
      "      accuracy                           0.73        91\n",
      "     macro avg       0.40      0.47      0.41        91\n",
      "  weighted avg       0.69      0.73      0.69        91\n",
      "\n",
      "\n",
      "Evaluating Model: WeightedEnsemble_L2\n",
      "Accuracy: 0.7253\n",
      "Precision: 0.6862\n",
      "Recall: 0.7253\n",
      "F1 Score: 0.6935\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       0.75      1.00      0.86         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       0.67      1.00      0.80         2\n",
      " CounterStrike       0.71      1.00      0.83         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.83      0.77      0.80        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.25      1.00      0.40         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "       SPankki       0.25      1.00      0.40         1\n",
      "         Steam       1.00      1.00      1.00         3\n",
      "    WeTransfer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.80      0.80      0.80         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.91      1.00      0.95        10\n",
      "          misc       0.33      0.33      0.33         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.87      1.00      0.93        13\n",
      "      unloaded       0.40      0.22      0.29         9\n",
      "\n",
      "      accuracy                           0.73        91\n",
      "     macro avg       0.40      0.47      0.41        91\n",
      "  weighted avg       0.69      0.73      0.69        91\n",
      "\n",
      "\n",
      "Evaluating Model: ExtraTreesGini\n",
      "Accuracy: 0.7143\n",
      "Precision: 0.6820\n",
      "Recall: 0.7143\n",
      "F1 Score: 0.6884\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.71      1.00      0.83         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.50      1.00      0.67         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      1.00      1.00         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.40      0.80      0.53         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.91      1.00      0.95        10\n",
      "          misc       0.33      0.33      0.33         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.87      1.00      0.93        13\n",
      "      unloaded       0.33      0.22      0.27         9\n",
      "\n",
      "      accuracy                           0.71        91\n",
      "     macro avg       0.44      0.47      0.45        91\n",
      "  weighted avg       0.68      0.71      0.69        91\n",
      "\n",
      "\n",
      "Evaluating Model: CatBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7033\n",
      "Precision: 0.7030\n",
      "Recall: 0.7033\n",
      "F1 Score: 0.6844\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.75      0.60      0.67         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.33      0.50         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "      Oldcircl       1.00      1.00      1.00         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.50      1.00      0.67         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.91      1.00      0.95        10\n",
      "          misc       0.25      0.33      0.29         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       1.00      0.92      0.96        13\n",
      "      unloaded       0.25      0.56      0.34         9\n",
      "\n",
      "      accuracy                           0.70        91\n",
      "     macro avg       0.52      0.50      0.50        91\n",
      "  weighted avg       0.70      0.70      0.68        91\n",
      "\n",
      "\n",
      "Evaluating Model: ExtraTreesEntr\n",
      "Accuracy: 0.6923\n",
      "Precision: 0.6635\n",
      "Recall: 0.6923\n",
      "F1 Score: 0.6690\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       0.75      1.00      0.86         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.57      0.80      0.67         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.50      1.00      0.67         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.44      0.80      0.57         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.91      1.00      0.95        10\n",
      "          misc       0.25      0.33      0.29         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.93      1.00      0.96        13\n",
      "      unloaded       0.22      0.22      0.22         9\n",
      "\n",
      "      accuracy                           0.69        91\n",
      "     macro avg       0.42      0.45      0.43        91\n",
      "  weighted avg       0.66      0.69      0.67        91\n",
      "\n",
      "\n",
      "Evaluating Model: NeuralNetTorch\n",
      "Accuracy: 0.6813\n",
      "Precision: 0.6900\n",
      "Recall: 0.6813\n",
      "F1 Score: 0.6692\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       0.75      1.00      0.86         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.62      1.00      0.77         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.50      1.00      0.67         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      " OrangeWebmail       0.00      0.00      0.00         0\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "          Post       0.00      0.00      0.00         0\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.33      0.50         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "       Windows       0.00      0.00      0.00         0\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.67      0.40      0.50         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       1.00      1.00      1.00         1\n",
      "     microsoft       0.90      0.90      0.90        10\n",
      "          misc       0.67      0.67      0.67         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "        paypal       0.00      0.00      0.00         0\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.76      1.00      0.87        13\n",
      "      unloaded       0.33      0.22      0.27         9\n",
      "\n",
      "      accuracy                           0.68        91\n",
      "     macro avg       0.42      0.42      0.40        91\n",
      "  weighted avg       0.69      0.68      0.67        91\n",
      "\n",
      "\n",
      "Evaluating Model: KNeighborsDist\n",
      "Accuracy: 0.6813\n",
      "Precision: 0.6852\n",
      "Recall: 0.6813\n",
      "F1 Score: 0.6712\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       0.60      1.00      0.75         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       0.67      1.00      0.80         2\n",
      " CounterStrike       0.60      0.60      0.60         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.89      0.62      0.73        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.25      1.00      0.40         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      1.00      1.00         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       0.80      1.00      0.89         4\n",
      "  errorMessage       1.00      0.80      0.89         5\n",
      "        fibank       0.00      0.00      0.00         0\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.91      1.00      0.95        10\n",
      "          misc       0.00      0.00      0.00         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.87      1.00      0.93        13\n",
      "      unloaded       0.43      0.33      0.38         9\n",
      "\n",
      "      accuracy                           0.68        91\n",
      "     macro avg       0.39      0.43      0.40        91\n",
      "  weighted avg       0.69      0.68      0.67        91\n",
      "\n",
      "\n",
      "Evaluating Model: RandomForestEntr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6813\n",
      "Precision: 0.6561\n",
      "Recall: 0.6813\n",
      "F1 Score: 0.6581\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       0.75      1.00      0.86         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.57      0.80      0.67         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.33      1.00      0.50         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.44      0.80      0.57         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.91      1.00      0.95        10\n",
      "          misc       0.20      0.33      0.25         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.86      0.92      0.89        13\n",
      "      unloaded       0.29      0.22      0.25         9\n",
      "\n",
      "      accuracy                           0.68        91\n",
      "     macro avg       0.43      0.47      0.43        91\n",
      "  weighted avg       0.66      0.68      0.66        91\n",
      "\n",
      "\n",
      "Evaluating Model: RandomForestGini\n",
      "Accuracy: 0.6813\n",
      "Precision: 0.6591\n",
      "Recall: 0.6813\n",
      "F1 Score: 0.6568\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       0.83      1.00      0.91         5\n",
      "    BancoInter       0.75      1.00      0.86         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.50      0.80      0.62         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.50      1.00      0.67         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.33      0.80      0.47         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.91      1.00      0.95        10\n",
      "          misc       0.20      0.33      0.25         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       1.00      0.92      0.96        13\n",
      "      unloaded       0.29      0.22      0.25         9\n",
      "\n",
      "      accuracy                           0.68        91\n",
      "     macro avg       0.43      0.47      0.43        91\n",
      "  weighted avg       0.66      0.68      0.66        91\n",
      "\n",
      "\n",
      "Evaluating Model: LightGBMXT\n",
      "Accuracy: 0.6703\n",
      "Precision: 0.6143\n",
      "Recall: 0.6703\n",
      "F1 Score: 0.6256\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.56      1.00      0.71         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.33      0.50         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.50      1.00      0.67         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       0.00      0.00      0.00         3\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.43      0.60      0.50         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.83      1.00      0.91        10\n",
      "          misc       0.33      0.67      0.44         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.76      1.00      0.87        13\n",
      "      unloaded       0.29      0.22      0.25         9\n",
      "\n",
      "      accuracy                           0.67        91\n",
      "     macro avg       0.42      0.46      0.42        91\n",
      "  weighted avg       0.61      0.67      0.63        91\n",
      "\n",
      "\n",
      "Evaluating Model: KNeighborsUnif\n",
      "Accuracy: 0.6593\n",
      "Precision: 0.6671\n",
      "Recall: 0.6593\n",
      "F1 Score: 0.6499\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Advanzia       1.00      1.00      1.00         5\n",
      "AmericanExpress       0.00      0.00      0.00         0\n",
      "     BancoInter       0.60      1.00      0.75         3\n",
      "      CarreBlue       0.00      0.00      0.00         2\n",
      " CirclWebServer       0.67      1.00      0.80         2\n",
      "  CounterStrike       0.60      0.60      0.60         5\n",
      "    EmiratesNBD       0.00      0.00      0.00         1\n",
      "            KBC       1.00      0.67      0.80         3\n",
      "            N26       0.88      0.54      0.67        13\n",
      "         Office       0.00      0.00      0.00         0\n",
      "       Oldcircl       0.20      1.00      0.33         1\n",
      "       OneDrive       0.00      0.00      0.00         1\n",
      "        Outlook       0.00      0.00      0.00         0\n",
      "        SPankki       1.00      1.00      1.00         1\n",
      "          Steam       1.00      1.00      1.00         3\n",
      "  TaggingServer       0.00      0.00      0.00         0\n",
      "     WellsFargo       0.00      0.00      0.00         1\n",
      "      ackouperm       0.80      1.00      0.89         4\n",
      "   errorMessage       0.67      0.80      0.73         5\n",
      "         fibank       0.00      0.00      0.00         0\n",
      "       formular       0.00      0.00      0.00         1\n",
      "         google       0.00      0.00      0.00         1\n",
      "      microsoft       0.91      1.00      0.95        10\n",
      "           misc       0.00      0.00      0.00         3\n",
      "      multilogo       0.00      0.00      0.00         1\n",
      "           news       0.00      0.00      0.00         1\n",
      "      rackspace       0.00      0.00      0.00         2\n",
      "     uncomplete       0.92      0.92      0.92        13\n",
      "       unloaded       0.38      0.33      0.35         9\n",
      "\n",
      "       accuracy                           0.66        91\n",
      "      macro avg       0.37      0.41      0.37        91\n",
      "   weighted avg       0.67      0.66      0.65        91\n",
      "\n",
      "\n",
      "Evaluating Model: XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6374\n",
      "Precision: 0.6643\n",
      "Recall: 0.6374\n",
      "F1 Score: 0.6332\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      0.80      0.89         5\n",
      "    BancoInter       0.75      1.00      0.86         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.50      0.60      0.55         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.33      0.50         3\n",
      "           N26       0.75      0.69      0.72        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.50      1.00      0.67         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.33      0.50         3\n",
      "    WeTransfer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.50      0.60      0.55         5\n",
      "        fibank       0.00      0.00      0.00         0\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.91      1.00      0.95        10\n",
      "          misc       0.29      0.67      0.40         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.92      0.92      0.92        13\n",
      "      unloaded       0.33      0.22      0.27         9\n",
      "\n",
      "      accuracy                           0.64        91\n",
      "     macro avg       0.41      0.40      0.38        91\n",
      "  weighted avg       0.66      0.64      0.63        91\n",
      "\n",
      "\n",
      "Evaluating Model: LightGBM\n",
      "Accuracy: 0.6264\n",
      "Precision: 0.6183\n",
      "Recall: 0.6264\n",
      "F1 Score: 0.6066\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      0.80      0.89         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.50      0.60      0.55         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.33      0.50         3\n",
      "           N26       0.80      0.62      0.70        13\n",
      "      Oldcircl       1.00      1.00      1.00         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       SPankki       0.50      1.00      0.67         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       0.67      1.00      0.80         4\n",
      "  errorMessage       0.44      0.80      0.57         5\n",
      "        fibank       0.00      0.00      0.00         0\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.83      1.00      0.91        10\n",
      "          misc       0.00      0.00      0.00         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.86      0.92      0.89        13\n",
      "      unloaded       0.17      0.22      0.19         9\n",
      "\n",
      "      accuracy                           0.63        91\n",
      "     macro avg       0.43      0.44      0.42        91\n",
      "  weighted avg       0.62      0.63      0.61        91\n",
      "\n",
      "\n",
      "Evaluating Model: LightGBMLarge\n",
      "Accuracy: 0.6154\n",
      "Precision: 0.6628\n",
      "Recall: 0.6154\n",
      "F1 Score: 0.6202\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      0.60      0.75         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.57      0.80      0.67         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.33      0.50         3\n",
      "           N26       0.73      0.62      0.67        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       1.00      1.00      1.00         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      " OrangeWebmail       0.00      0.00      0.00         0\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       0.75      0.75      0.75         4\n",
      "       bitcoin       0.00      0.00      0.00         0\n",
      "  errorMessage       0.50      0.60      0.55         5\n",
      "        fibank       0.00      0.00      0.00         0\n",
      "      formular       0.50      1.00      0.67         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.75      0.90      0.82        10\n",
      "          misc       1.00      0.33      0.50         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.92      0.92      0.92        13\n",
      "      unloaded       0.17      0.22      0.19         9\n",
      "\n",
      "      accuracy                           0.62        91\n",
      "     macro avg       0.43      0.39      0.39        91\n",
      "  weighted avg       0.66      0.62      0.62        91\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    top_k_accuracy_score,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Combine image and text embeddings into a single feature set\n",
    "df[\"combined_embedding\"] = df.apply(\n",
    "    lambda row: np.hstack([row[\"image_embedding\"], row[\"text_embedding\"]]), axis=1\n",
    ")\n",
    "\n",
    "# Prepare DataFrame for AutoGluon\n",
    "embedding_cols = pd.DataFrame(df[\"combined_embedding\"].to_list())\n",
    "embedding_cols.columns = [f\"feature_{i}\" for i in range(embedding_cols.shape[1])]\n",
    "df_for_autogluon = pd.concat([embedding_cols, df[\"brand\"]], axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = df_for_autogluon.sample(frac=0.8, random_state=42)\n",
    "test_data = df_for_autogluon.drop(train_data.index)\n",
    "\n",
    "# Define label column\n",
    "label = \"brand\"\n",
    "\n",
    "# Train AutoGluon model\n",
    "predictor = TabularPredictor(label=label).fit(train_data)\n",
    "\n",
    "# Get leaderboard\n",
    "leaderboard = predictor.leaderboard(test_data, silent=True)\n",
    "print(\"Leaderboard of Models:\")\n",
    "print(leaderboard)\n",
    "\n",
    "# Test labels and data without the label column\n",
    "test_labels = test_data[label]\n",
    "test_data_no_label = test_data.drop(columns=[label])\n",
    "\n",
    "# Unique labels (needed for ROC-AUC alignment)\n",
    "unique_labels = predictor.class_labels\n",
    "\n",
    "# Evaluate each model individually\n",
    "for model_name in leaderboard[\"model\"]:\n",
    "    print(f\"\\nEvaluating Model: {model_name}\")\n",
    "    \n",
    "    # Predict using the specific model\n",
    "    predictions = predictor.predict(test_data_no_label, model=model_name)\n",
    "    probs = predictor.predict_proba(test_data_no_label, model=model_name)\n",
    "\n",
    "    # Ensure alignment of probabilities and labels\n",
    "    probs_aligned = probs.loc[:, unique_labels].to_numpy()\n",
    "    test_labels_binarized = label_binarize(test_labels, classes=unique_labels)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions, average=\"weighted\")\n",
    "    recall = recall_score(test_labels, predictions, average=\"weighted\")\n",
    "    f1 = f1_score(test_labels, predictions, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(test_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# save classification_report(test_labels, predictions)\n",
    "report = classification_report(test_labels, predictions, output_dict=True)\n",
    "pd.DataFrame(report).transpose().to_csv(\"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_multimedia.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autogluon with image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241208_001352\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.4.0: Wed Feb 21 21:44:06 PST 2024; root:xnu-10063.101.15~2/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.78 GB / 16.00 GB (23.6%)\n",
      "Disk Space Avail:   112.62 GB / 931.48 GB (12.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Volumes/T7/DLCOURSEWORK/AutogluonModels/ag-20241208_001352\"\n",
      "Train Data Rows:    366\n",
      "Train Data Columns: 512\n",
      "Label Column:       brand\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 42) unique label values:  ['KBC', 'formular', 'Outlook', 'misc', 'N26', 'unloaded', 'Office', 'TaggingServer', 'errorMessage', 'uncomplete']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 2 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 2 examples. AutoGluon will only keep 39 out of 42 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 2 examples that will be kept for training models: 0.9918032786885246\n",
      "Train Data Class Count: 39\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3869.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.71 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 512 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 512 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t512 features in original data used to generate 512 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.71 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 290, Val Rows: 73\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.6575\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.7123\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.7808\t = Validation score   (accuracy)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.7397\t = Validation score   (accuracy)\n",
      "\t6.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.6849\t = Validation score   (accuracy)\n",
      "\t7.47s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.726\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7534\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.7123\t = Validation score   (accuracy)\n",
      "\t327.88s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7123\t = Validation score   (accuracy)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7534\t = Validation score   (accuracy)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.7397\t = Validation score   (accuracy)\n",
      "\t11.75s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.7808\t = Validation score   (accuracy)\n",
      "\t2.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.6575\t = Validation score   (accuracy)\n",
      "\t28.06s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.5, 'RandomForestEntr': 0.5}\n",
      "\t0.7945\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 387.94s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1160.1 rows/s (73 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Volumes/T7/DLCOURSEWORK/AutogluonModels/ag-20241208_001352\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaderboard of Models:\n",
      "                  model  score_test  score_val eval_metric  pred_time_test  \\\n",
      "0        ExtraTreesEntr    0.714286   0.753425    accuracy        0.055167   \n",
      "1       NeuralNetFastAI    0.703297   0.780822    accuracy        0.009560   \n",
      "2   WeightedEnsemble_L2    0.703297   0.794521    accuracy        0.068064   \n",
      "3        NeuralNetTorch    0.692308   0.780822    accuracy        0.011495   \n",
      "4        KNeighborsDist    0.681319   0.712329    accuracy        0.007625   \n",
      "5      RandomForestEntr    0.681319   0.753425    accuracy        0.050731   \n",
      "6      RandomForestGini    0.681319   0.726027    accuracy        0.061158   \n",
      "7        ExtraTreesGini    0.681319   0.712329    accuracy        0.065458   \n",
      "8            LightGBMXT    0.670330   0.739726    accuracy        0.023267   \n",
      "9        KNeighborsUnif    0.659341   0.657534    accuracy        0.006299   \n",
      "10             CatBoost    0.648352   0.712329    accuracy        0.038296   \n",
      "11        LightGBMLarge    0.637363   0.657534    accuracy        0.101335   \n",
      "12              XGBoost    0.626374   0.739726    accuracy        0.125354   \n",
      "13             LightGBM    0.593407   0.684932    accuracy        0.011028   \n",
      "\n",
      "    pred_time_val    fit_time  pred_time_test_marginal  \\\n",
      "0        0.026870    0.392348                 0.055167   \n",
      "1        0.007141    0.612971                 0.009560   \n",
      "2        0.062923    1.254696                 0.007773   \n",
      "3        0.005374    2.415315                 0.011495   \n",
      "4        0.006236    0.021783                 0.007625   \n",
      "5        0.055408    0.595410                 0.050731   \n",
      "6        0.026920    0.596330                 0.061158   \n",
      "7        0.026789    0.406625                 0.065458   \n",
      "8        0.004964    6.178979                 0.023267   \n",
      "9        0.005257    0.020295                 0.006299   \n",
      "10       0.009681  327.883882                 0.038296   \n",
      "11       0.019378   28.060725                 0.101335   \n",
      "12       0.003283   11.745555                 0.125354   \n",
      "13       0.002104    7.470853                 0.011028   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.026870           0.392348            1       True   \n",
      "1                 0.007141           0.612971            1       True   \n",
      "2                 0.000374           0.046315            2       True   \n",
      "3                 0.005374           2.415315            1       True   \n",
      "4                 0.006236           0.021783            1       True   \n",
      "5                 0.055408           0.595410            1       True   \n",
      "6                 0.026920           0.596330            1       True   \n",
      "7                 0.026789           0.406625            1       True   \n",
      "8                 0.004964           6.178979            1       True   \n",
      "9                 0.005257           0.020295            1       True   \n",
      "10                0.009681         327.883882            1       True   \n",
      "11                0.019378          28.060725            1       True   \n",
      "12                0.003283          11.745555            1       True   \n",
      "13                0.002104           7.470853            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0          10  \n",
      "1           3  \n",
      "2          14  \n",
      "3          12  \n",
      "4           2  \n",
      "5           7  \n",
      "6           6  \n",
      "7           9  \n",
      "8           4  \n",
      "9           1  \n",
      "10          8  \n",
      "11         13  \n",
      "12         11  \n",
      "13          5  \n",
      "\n",
      "Evaluating Model: ExtraTreesEntr\n",
      "Accuracy: 0.7143\n",
      "Precision: 0.6867\n",
      "Recall: 0.7143\n",
      "F1 Score: 0.6885\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.71      1.00      0.83         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "      Oldcircl       1.00      1.00      1.00         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.45      1.00      0.62         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.83      1.00      0.91        10\n",
      "          misc       0.14      0.33      0.20         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       1.00      1.00      1.00        13\n",
      "      unloaded       0.25      0.22      0.24         9\n",
      "\n",
      "      accuracy                           0.71        91\n",
      "     macro avg       0.49      0.50      0.49        91\n",
      "  weighted avg       0.69      0.71      0.69        91\n",
      "\n",
      "\n",
      "Evaluating Model: NeuralNetFastAI\n",
      "Accuracy: 0.7033\n",
      "Precision: 0.6762\n",
      "Recall: 0.7033\n",
      "F1 Score: 0.6808\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       0.71      1.00      0.83         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.60      0.60      0.60         5\n",
      "       DropBox       0.00      0.00      0.00         0\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.50      1.00      0.67         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      1.00      1.00         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.44      0.80      0.57         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "          hsbc       0.00      0.00      0.00         0\n",
      "     microsoft       0.91      1.00      0.95        10\n",
      "          misc       1.00      0.67      0.80         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.87      1.00      0.93        13\n",
      "      unloaded       0.25      0.22      0.24         9\n",
      "\n",
      "      accuracy                           0.70        91\n",
      "     macro avg       0.42      0.44      0.42        91\n",
      "  weighted avg       0.68      0.70      0.68        91\n",
      "\n",
      "\n",
      "Evaluating Model: WeightedEnsemble_L2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7033\n",
      "Precision: 0.6663\n",
      "Recall: 0.7033\n",
      "F1 Score: 0.6774\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       0.83      1.00      0.91         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.60      0.60      0.60         5\n",
      "       DropBox       0.00      0.00      0.00         0\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.50      1.00      0.67         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      1.00      1.00         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.44      0.80      0.57         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "          hsbc       0.00      0.00      0.00         0\n",
      "     microsoft       0.91      1.00      0.95        10\n",
      "          misc       0.50      0.67      0.57         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.87      1.00      0.93        13\n",
      "      unloaded       0.25      0.22      0.24         9\n",
      "\n",
      "      accuracy                           0.70        91\n",
      "     macro avg       0.40      0.44      0.41        91\n",
      "  weighted avg       0.67      0.70      0.68        91\n",
      "\n",
      "\n",
      "Evaluating Model: NeuralNetTorch\n",
      "Accuracy: 0.6923\n",
      "Precision: 0.7021\n",
      "Recall: 0.6923\n",
      "F1 Score: 0.6891\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       1.00      1.00      1.00         5\n",
      "       DropBox       0.00      0.00      0.00         0\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       1.00      1.00      1.00         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       0.50      0.67      0.57         3\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "           dhl       0.00      0.00      0.00         0\n",
      "  errorMessage       0.50      0.40      0.44         5\n",
      "        fibank       0.00      0.00      0.00         0\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.50      1.00      0.67         1\n",
      "     microsoft       0.91      1.00      0.95        10\n",
      "          misc       0.50      0.33      0.40         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.81      1.00      0.90        13\n",
      "      unloaded       0.40      0.22      0.29         9\n",
      "\n",
      "      accuracy                           0.69        91\n",
      "     macro avg       0.46      0.46      0.46        91\n",
      "  weighted avg       0.70      0.69      0.69        91\n",
      "\n",
      "\n",
      "Evaluating Model: KNeighborsDist\n",
      "Accuracy: 0.6813\n",
      "Precision: 0.6777\n",
      "Recall: 0.6813\n",
      "F1 Score: 0.6618\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       0.60      1.00      0.75         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.71      1.00      0.83         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.33      0.50         3\n",
      "           N26       0.90      0.69      0.78        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.25      1.00      0.40         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      " OrangeWebmail       0.00      0.00      0.00         0\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       0.80      1.00      0.89         4\n",
      "  errorMessage       0.60      0.60      0.60         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.91      1.00      0.95        10\n",
      "          misc       0.00      0.00      0.00         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.81      1.00      0.90        13\n",
      "      unloaded       0.50      0.33      0.40         9\n",
      "\n",
      "      accuracy                           0.68        91\n",
      "     macro avg       0.40      0.42      0.39        91\n",
      "  weighted avg       0.68      0.68      0.66        91\n",
      "\n",
      "\n",
      "Evaluating Model: RandomForestEntr\n",
      "Accuracy: 0.6813\n",
      "Precision: 0.6550\n",
      "Recall: 0.6813\n",
      "F1 Score: 0.6602\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.67      0.80      0.73         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       0.00      0.00      0.00         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.50      1.00      0.67         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.44      0.80      0.57         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.91      1.00      0.95        10\n",
      "          misc       0.12      0.33      0.18         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.93      1.00      0.96        13\n",
      "      unloaded       0.38      0.33      0.35         9\n",
      "\n",
      "      accuracy                           0.68        91\n",
      "     macro avg       0.41      0.45      0.42        91\n",
      "  weighted avg       0.65      0.68      0.66        91\n",
      "\n",
      "\n",
      "Evaluating Model: RandomForestGini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6813\n",
      "Precision: 0.6551\n",
      "Recall: 0.6813\n",
      "F1 Score: 0.6573\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.60      0.60      0.60         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.75      0.69      0.72        13\n",
      "      Oldcircl       1.00      1.00      1.00         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.40      0.80      0.53         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.67      1.00      0.80        10\n",
      "          misc       0.17      0.33      0.22         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       1.00      0.92      0.96        13\n",
      "      unloaded       0.30      0.33      0.32         9\n",
      "\n",
      "      accuracy                           0.68        91\n",
      "     macro avg       0.48      0.48      0.47        91\n",
      "  weighted avg       0.66      0.68      0.66        91\n",
      "\n",
      "\n",
      "Evaluating Model: ExtraTreesGini\n",
      "Accuracy: 0.6813\n",
      "Precision: 0.6665\n",
      "Recall: 0.6813\n",
      "F1 Score: 0.6623\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.60      0.60      0.60         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "      Oldcircl       1.00      1.00      1.00         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.33      0.80      0.47         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.71      1.00      0.83        10\n",
      "          misc       0.25      0.33      0.29         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       1.00      0.92      0.96        13\n",
      "      unloaded       0.27      0.33      0.30         9\n",
      "\n",
      "      accuracy                           0.68        91\n",
      "     macro avg       0.50      0.50      0.49        91\n",
      "  weighted avg       0.67      0.68      0.66        91\n",
      "\n",
      "\n",
      "Evaluating Model: LightGBMXT\n",
      "Accuracy: 0.6703\n",
      "Precision: 0.6395\n",
      "Recall: 0.6703\n",
      "F1 Score: 0.6412\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      0.80      0.89         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.67      0.80      0.73         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.33      0.50         3\n",
      "           N26       0.75      0.69      0.72        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       1.00      1.00      1.00         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.44      0.80      0.57         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.77      1.00      0.87        10\n",
      "          misc       0.33      0.33      0.33         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.81      1.00      0.90        13\n",
      "      unloaded       0.18      0.22      0.20         9\n",
      "\n",
      "      accuracy                           0.67        91\n",
      "     macro avg       0.48      0.47      0.46        91\n",
      "  weighted avg       0.64      0.67      0.64        91\n",
      "\n",
      "\n",
      "Evaluating Model: KNeighborsUnif\n",
      "Accuracy: 0.6593\n",
      "Precision: 0.6839\n",
      "Recall: 0.6593\n",
      "F1 Score: 0.6521\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Advanzia       1.00      1.00      1.00         5\n",
      "AmericanExpress       0.00      0.00      0.00         0\n",
      "     BancoInter       0.50      1.00      0.67         3\n",
      "      CarreBlue       0.00      0.00      0.00         2\n",
      " CirclWebServer       1.00      1.00      1.00         2\n",
      "  CounterStrike       0.67      0.80      0.73         5\n",
      "    EmiratesNBD       0.00      0.00      0.00         1\n",
      "            KBC       1.00      0.33      0.50         3\n",
      "            N26       0.89      0.62      0.73        13\n",
      "         Office       0.00      0.00      0.00         0\n",
      "       Oldcircl       0.20      1.00      0.33         1\n",
      "       OneDrive       0.00      0.00      0.00         1\n",
      "  OrangeWebmail       0.00      0.00      0.00         0\n",
      "        Outlook       0.00      0.00      0.00         0\n",
      "        SPankki       1.00      1.00      1.00         1\n",
      "          Steam       1.00      0.67      0.80         3\n",
      "  TaggingServer       0.00      0.00      0.00         0\n",
      "     WellsFargo       0.00      0.00      0.00         1\n",
      "      ackouperm       0.80      1.00      0.89         4\n",
      "   errorMessage       0.57      0.80      0.67         5\n",
      "       formular       0.00      0.00      0.00         1\n",
      "         google       0.00      0.00      0.00         1\n",
      "      microsoft       0.91      1.00      0.95        10\n",
      "           misc       0.00      0.00      0.00         3\n",
      "      multilogo       0.00      0.00      0.00         1\n",
      "           news       0.00      0.00      0.00         1\n",
      "         paypal       0.00      0.00      0.00         0\n",
      "      rackspace       0.00      0.00      0.00         2\n",
      "     uncomplete       0.92      0.92      0.92        13\n",
      "       unloaded       0.50      0.33      0.40         9\n",
      "\n",
      "       accuracy                           0.66        91\n",
      "      macro avg       0.37      0.38      0.35        91\n",
      "   weighted avg       0.68      0.66      0.65        91\n",
      "\n",
      "\n",
      "Evaluating Model: CatBoost\n",
      "Accuracy: 0.6484\n",
      "Precision: 0.6575\n",
      "Recall: 0.6484\n",
      "F1 Score: 0.6324\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      0.80      0.89         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.40      0.40      0.40         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.33      0.50         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "      Oldcircl       0.33      1.00      0.50         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.33      0.50         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.40      0.80      0.53         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.83      1.00      0.91        10\n",
      "          misc       0.20      0.33      0.25         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       1.00      1.00      1.00        13\n",
      "      unloaded       0.21      0.33      0.26         9\n",
      "\n",
      "      accuracy                           0.65        91\n",
      "     macro avg       0.45      0.44      0.42        91\n",
      "  weighted avg       0.66      0.65      0.63        91\n",
      "\n",
      "\n",
      "Evaluating Model: LightGBMLarge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6374\n",
      "Precision: 0.6348\n",
      "Recall: 0.6374\n",
      "F1 Score: 0.6229\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      0.60      0.75         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.57      0.80      0.67         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.33      0.50         3\n",
      "           N26       0.64      0.69      0.67        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       1.00      1.00      1.00         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      " OrangeWebmail       0.00      0.00      0.00         0\n",
      "       SPankki       0.50      1.00      0.67         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.67      0.80      0.73         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.83      1.00      0.91        10\n",
      "          misc       0.00      0.00      0.00         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.92      0.92      0.92        13\n",
      "      unloaded       0.15      0.22      0.18         9\n",
      "\n",
      "      accuracy                           0.64        91\n",
      "     macro avg       0.42      0.41      0.40        91\n",
      "  weighted avg       0.63      0.64      0.62        91\n",
      "\n",
      "\n",
      "Evaluating Model: XGBoost\n",
      "Accuracy: 0.6264\n",
      "Precision: 0.6714\n",
      "Recall: 0.6264\n",
      "F1 Score: 0.6292\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      0.80      0.89         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.57      0.80      0.67         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.33      0.50         3\n",
      "           N26       0.73      0.62      0.67        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       1.00      1.00      1.00         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "          Post       0.00      0.00      0.00         0\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.33      0.50         3\n",
      "    WeTransfer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       0.80      1.00      0.89         4\n",
      "       bitcoin       0.00      0.00      0.00         0\n",
      "  errorMessage       0.38      0.60      0.46         5\n",
      "        fibank       0.00      0.00      0.00         0\n",
      "      formular       0.50      1.00      0.67         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.91      1.00      0.95        10\n",
      "          misc       0.20      0.33      0.25         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.92      0.85      0.88        13\n",
      "      unloaded       0.40      0.22      0.29         9\n",
      "\n",
      "      accuracy                           0.63        91\n",
      "     macro avg       0.41      0.40      0.39        91\n",
      "  weighted avg       0.67      0.63      0.63        91\n",
      "\n",
      "\n",
      "Evaluating Model: LightGBM\n",
      "Accuracy: 0.5934\n",
      "Precision: 0.5308\n",
      "Recall: 0.5934\n",
      "F1 Score: 0.5471\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      0.60      0.75         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.50      0.60      0.55         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       0.00      0.00      0.00         3\n",
      "           N26       0.67      0.62      0.64        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.00      0.00      0.00         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.57      0.80      0.67         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.77      1.00      0.87        10\n",
      "          misc       0.00      0.00      0.00         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.52      0.92      0.67        13\n",
      "      unloaded       0.20      0.22      0.21         9\n",
      "\n",
      "      accuracy                           0.59        91\n",
      "     macro avg       0.37      0.38      0.37        91\n",
      "  weighted avg       0.53      0.59      0.55        91\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    top_k_accuracy_score,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Prepare DataFrame for AutoGluon using only image embeddings\n",
    "embedding_cols = pd.DataFrame(df[\"image_embedding\"].to_list())\n",
    "embedding_cols.columns = [f\"feature_{i}\" for i in range(embedding_cols.shape[1])]\n",
    "df_for_autogluon = pd.concat([embedding_cols, df[\"brand\"]], axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = df_for_autogluon.sample(frac=0.8, random_state=42)\n",
    "test_data = df_for_autogluon.drop(train_data.index)\n",
    "\n",
    "# Define label column\n",
    "label = \"brand\"\n",
    "\n",
    "# Train AutoGluon model\n",
    "predictor = TabularPredictor(label=label).fit(train_data)\n",
    "\n",
    "# Get leaderboard\n",
    "leaderboard = predictor.leaderboard(test_data, silent=True)\n",
    "print(\"Leaderboard of Models:\")\n",
    "print(leaderboard)\n",
    "\n",
    "# Test labels and data without the label column\n",
    "test_labels = test_data[label]\n",
    "test_data_no_label = test_data.drop(columns=[label])\n",
    "\n",
    "# Unique labels (needed for ROC-AUC alignment)\n",
    "unique_labels = predictor.class_labels\n",
    "\n",
    "# Evaluate each model individually\n",
    "for model_name in leaderboard[\"model\"]:\n",
    "    print(f\"\\nEvaluating Model: {model_name}\")\n",
    "    \n",
    "    # Predict using the specific model\n",
    "    predictions = predictor.predict(test_data_no_label, model=model_name)\n",
    "    probs = predictor.predict_proba(test_data_no_label, model=model_name)\n",
    "\n",
    "    # Ensure alignment of probabilities and labels\n",
    "    probs_aligned = probs.loc[:, unique_labels].to_numpy()\n",
    "    test_labels_binarized = label_binarize(test_labels, classes=unique_labels)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions, average=\"weighted\")\n",
    "    recall = recall_score(test_labels, predictions, average=\"weighted\")\n",
    "    f1 = f1_score(test_labels, predictions, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(test_labels, predictions))\n",
    "\n",
    "# save classification_report(test_labels, predictions)\n",
    "report = classification_report(test_labels, predictions, output_dict=True)\n",
    "pd.DataFrame(report).transpose().to_csv(\"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_image.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autogluon with textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241208_002022\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.4.0: Wed Feb 21 21:44:06 PST 2024; root:xnu-10063.101.15~2/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.56 GB / 16.00 GB (22.3%)\n",
      "Disk Space Avail:   112.49 GB / 931.48 GB (12.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Volumes/T7/DLCOURSEWORK/AutogluonModels/ag-20241208_002022\"\n",
      "Train Data Rows:    366\n",
      "Train Data Columns: 512\n",
      "Label Column:       brand\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 42) unique label values:  ['KBC', 'formular', 'Outlook', 'misc', 'N26', 'unloaded', 'Office', 'TaggingServer', 'errorMessage', 'uncomplete']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 2 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 2 examples. AutoGluon will only keep 39 out of 42 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 2 examples that will be kept for training models: 0.9918032786885246\n",
      "Train Data Class Count: 39\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3604.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.71 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 512 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 512 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t512 features in original data used to generate 512 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.71 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 290, Val Rows: 73\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.5616\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.589\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.6712\t = Validation score   (accuracy)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.6986\t = Validation score   (accuracy)\n",
      "\t5.52s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.6164\t = Validation score   (accuracy)\n",
      "\t6.87s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.6301\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.6438\t = Validation score   (accuracy)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.6849\t = Validation score   (accuracy)\n",
      "\t339.32s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6575\t = Validation score   (accuracy)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6712\t = Validation score   (accuracy)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.6575\t = Validation score   (accuracy)\n",
      "\t12.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.6301\t = Validation score   (accuracy)\n",
      "\t1.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.6027\t = Validation score   (accuracy)\n",
      "\t35.34s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'LightGBMXT': 0.667, 'ExtraTreesEntr': 0.333}\n",
      "\t0.7123\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 405.14s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2073.6 rows/s (73 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Volumes/T7/DLCOURSEWORK/AutogluonModels/ag-20241208_002022\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaderboard of Models:\n",
      "                  model  score_test  score_val eval_metric  pred_time_test  \\\n",
      "0        ExtraTreesEntr    0.648352   0.671233    accuracy        0.054372   \n",
      "1        ExtraTreesGini    0.637363   0.657534    accuracy        0.065196   \n",
      "2       NeuralNetFastAI    0.626374   0.671233    accuracy        0.009309   \n",
      "3      RandomForestGini    0.626374   0.630137    accuracy        0.065241   \n",
      "4      RandomForestEntr    0.615385   0.643836    accuracy        0.050736   \n",
      "5        NeuralNetTorch    0.593407   0.630137    accuracy        0.010454   \n",
      "6        KNeighborsDist    0.582418   0.589041    accuracy        0.010795   \n",
      "7              LightGBM    0.582418   0.616438    accuracy        0.020953   \n",
      "8              CatBoost    0.582418   0.684932    accuracy        0.037545   \n",
      "9        KNeighborsUnif    0.571429   0.561644    accuracy        0.007898   \n",
      "10  WeightedEnsemble_L2    0.571429   0.712329    accuracy        0.109503   \n",
      "11           LightGBMXT    0.560440   0.698630    accuracy        0.046997   \n",
      "12              XGBoost    0.560440   0.657534    accuracy        0.147241   \n",
      "13        LightGBMLarge    0.538462   0.602740    accuracy        0.099190   \n",
      "\n",
      "    pred_time_val    fit_time  pred_time_test_marginal  \\\n",
      "0        0.026902    0.367403                 0.054372   \n",
      "1        0.025855    0.422361                 0.065196   \n",
      "2        0.004289    0.547932                 0.009309   \n",
      "3        0.024707    0.617856                 0.065241   \n",
      "4        0.025853    0.593562                 0.050736   \n",
      "5        0.004708    1.354632                 0.010454   \n",
      "6        0.005021    0.021561                 0.010795   \n",
      "7        0.003073    6.871498                 0.020953   \n",
      "8        0.010927  339.322766                 0.037545   \n",
      "9        0.003360    0.020713                 0.007898   \n",
      "10       0.035205    5.931017                 0.008134   \n",
      "11       0.007963    5.516347                 0.046997   \n",
      "12       0.004693   12.341615                 0.147241   \n",
      "13       0.019899   35.336127                 0.099190   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.026902           0.367403            1       True   \n",
      "1                 0.025855           0.422361            1       True   \n",
      "2                 0.004289           0.547932            1       True   \n",
      "3                 0.024707           0.617856            1       True   \n",
      "4                 0.025853           0.593562            1       True   \n",
      "5                 0.004708           1.354632            1       True   \n",
      "6                 0.005021           0.021561            1       True   \n",
      "7                 0.003073           6.871498            1       True   \n",
      "8                 0.010927         339.322766            1       True   \n",
      "9                 0.003360           0.020713            1       True   \n",
      "10                0.000340           0.047267            2       True   \n",
      "11                0.007963           5.516347            1       True   \n",
      "12                0.004693          12.341615            1       True   \n",
      "13                0.019899          35.336127            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0          10  \n",
      "1           9  \n",
      "2           3  \n",
      "3           6  \n",
      "4           7  \n",
      "5          12  \n",
      "6           2  \n",
      "7           5  \n",
      "8           8  \n",
      "9           1  \n",
      "10         14  \n",
      "11          4  \n",
      "12         11  \n",
      "13         13  \n",
      "\n",
      "Evaluating Model: ExtraTreesEntr\n",
      "Accuracy: 0.6484\n",
      "Precision: 0.6195\n",
      "Recall: 0.6484\n",
      "F1 Score: 0.6212\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       0.75      1.00      0.86         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.43      0.60      0.50         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.50      1.00      0.67         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "       SPankki       0.50      1.00      0.67         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.30      0.60      0.40         5\n",
      "        fibank       0.00      0.00      0.00         0\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.89      0.80      0.84        10\n",
      "          misc       0.33      0.33      0.33         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.72      1.00      0.84        13\n",
      "      unloaded       0.29      0.22      0.25         9\n",
      "\n",
      "      accuracy                           0.65        91\n",
      "     macro avg       0.39      0.43      0.40        91\n",
      "  weighted avg       0.62      0.65      0.62        91\n",
      "\n",
      "\n",
      "Evaluating Model: ExtraTreesGini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6374\n",
      "Precision: 0.5923\n",
      "Recall: 0.6374\n",
      "F1 Score: 0.6011\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       0.60      1.00      0.75         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.75      0.60      0.67         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "      Oldcircl       1.00      1.00      1.00         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      1.00      1.00         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.40      0.80      0.53         5\n",
      "        fibank       0.00      0.00      0.00         0\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.80      0.80      0.80        10\n",
      "          misc       0.00      0.00      0.00         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.57      0.92      0.71        13\n",
      "      unloaded       0.14      0.11      0.12         9\n",
      "\n",
      "      accuracy                           0.64        91\n",
      "     macro avg       0.41      0.43      0.41        91\n",
      "  weighted avg       0.59      0.64      0.60        91\n",
      "\n",
      "\n",
      "Evaluating Model: NeuralNetFastAI\n",
      "Accuracy: 0.6264\n",
      "Precision: 0.6063\n",
      "Recall: 0.6264\n",
      "F1 Score: 0.5957\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       0.83      1.00      0.91         5\n",
      "    BancoInter       0.60      1.00      0.75         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.50      0.60      0.55         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.90      0.69      0.78        13\n",
      "      Oldcircl       0.50      1.00      0.67         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      " OrangeWebmail       0.00      0.00      0.00         0\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       0.80      1.00      0.89         4\n",
      "  errorMessage       0.50      0.20      0.29         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.89      0.80      0.84        10\n",
      "          misc       0.33      0.33      0.33         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.57      1.00      0.72        13\n",
      "      unloaded       0.29      0.22      0.25         9\n",
      "\n",
      "      accuracy                           0.63        91\n",
      "     macro avg       0.40      0.41      0.39        91\n",
      "  weighted avg       0.61      0.63      0.60        91\n",
      "\n",
      "\n",
      "Evaluating Model: RandomForestGini\n",
      "Accuracy: 0.6264\n",
      "Precision: 0.5689\n",
      "Recall: 0.6264\n",
      "F1 Score: 0.5812\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       0.75      1.00      0.86         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.50      0.40      0.44         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "      Oldcircl       0.50      1.00      0.67         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       0.80      1.00      0.89         4\n",
      "  errorMessage       0.40      0.80      0.53         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.90      0.90      0.90        10\n",
      "          misc       0.00      0.00      0.00         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.59      1.00      0.74        13\n",
      "      unloaded       0.00      0.00      0.00         9\n",
      "\n",
      "      accuracy                           0.63        91\n",
      "     macro avg       0.39      0.43      0.40        91\n",
      "  weighted avg       0.57      0.63      0.58        91\n",
      "\n",
      "\n",
      "Evaluating Model: RandomForestEntr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6154\n",
      "Precision: 0.5983\n",
      "Recall: 0.6154\n",
      "F1 Score: 0.5924\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      0.80      0.89         5\n",
      "    BancoInter       0.75      1.00      0.86         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.33      0.40      0.36         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.80      0.62      0.70        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.50      1.00      0.67         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.44      0.80      0.57         5\n",
      "        fibank       0.00      0.00      0.00         0\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.89      0.80      0.84        10\n",
      "          misc       0.17      0.33      0.22         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.68      1.00      0.81        13\n",
      "      unloaded       0.12      0.11      0.12         9\n",
      "\n",
      "      accuracy                           0.62        91\n",
      "     macro avg       0.41      0.43      0.41        91\n",
      "  weighted avg       0.60      0.62      0.59        91\n",
      "\n",
      "\n",
      "Evaluating Model: NeuralNetTorch\n",
      "Accuracy: 0.5934\n",
      "Precision: 0.6085\n",
      "Recall: 0.5934\n",
      "F1 Score: 0.5739\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      1.00      1.00         5\n",
      "    BancoInter       0.60      1.00      0.75         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.50      0.60      0.55         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "      Oldcircl       0.50      1.00      0.67         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      " OrangeWebmail       0.00      0.00      0.00         0\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "       Windows       0.00      0.00      0.00         0\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "       android       0.00      0.00      0.00         0\n",
      "  errorMessage       1.00      0.20      0.33         5\n",
      "        fibank       0.00      0.00      0.00         0\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "          hsbc       0.00      0.00      0.00         0\n",
      "     microsoft       0.89      0.80      0.84        10\n",
      "          misc       0.00      0.00      0.00         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.62      1.00      0.76        13\n",
      "      unloaded       0.00      0.00      0.00         9\n",
      "\n",
      "      accuracy                           0.59        91\n",
      "     macro avg       0.35      0.34      0.33        91\n",
      "  weighted avg       0.61      0.59      0.57        91\n",
      "\n",
      "\n",
      "Evaluating Model: KNeighborsDist\n",
      "Accuracy: 0.5824\n",
      "Precision: 0.6372\n",
      "Recall: 0.5824\n",
      "F1 Score: 0.5765\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Advanzia       1.00      1.00      1.00         5\n",
      "AmericanExpress       0.00      0.00      0.00         0\n",
      "     BancoInter       0.75      1.00      0.86         3\n",
      "      CarreBlue       0.00      0.00      0.00         2\n",
      " CirclWebServer       1.00      1.00      1.00         2\n",
      "  CounterStrike       0.50      0.20      0.29         5\n",
      "    EmiratesNBD       0.00      0.00      0.00         1\n",
      "       FrImpots       0.00      0.00      0.00         0\n",
      "            KBC       1.00      0.67      0.80         3\n",
      "            N26       0.89      0.62      0.73        13\n",
      "       Oldcircl       0.50      1.00      0.67         1\n",
      "       OneDrive       0.00      0.00      0.00         1\n",
      "  OrangeWebmail       0.00      0.00      0.00         0\n",
      "        Outlook       0.00      0.00      0.00         0\n",
      "        SPankki       0.50      1.00      0.67         1\n",
      "          Steam       1.00      1.00      1.00         3\n",
      "  TaggingServer       0.00      0.00      0.00         0\n",
      "     WellsFargo       0.00      0.00      0.00         1\n",
      "      ackouperm       1.00      0.75      0.86         4\n",
      "        android       0.00      0.00      0.00         0\n",
      "   errorMessage       1.00      0.20      0.33         5\n",
      "         fibank       0.00      0.00      0.00         0\n",
      "       formular       0.00      0.00      0.00         1\n",
      "         google       0.00      0.00      0.00         1\n",
      "      microsoft       0.89      0.80      0.84        10\n",
      "           misc       0.00      0.00      0.00         3\n",
      "      multilogo       0.00      0.00      0.00         1\n",
      "           news       0.00      0.00      0.00         1\n",
      "         paypal       0.00      0.00      0.00         0\n",
      "      rackspace       0.00      0.00      0.00         2\n",
      "     uncomplete       0.55      0.92      0.69        13\n",
      "       unloaded       0.30      0.33      0.32         9\n",
      "\n",
      "       accuracy                           0.58        91\n",
      "      macro avg       0.34      0.33      0.31        91\n",
      "   weighted avg       0.64      0.58      0.58        91\n",
      "\n",
      "\n",
      "Evaluating Model: LightGBM\n",
      "Accuracy: 0.5824\n",
      "Precision: 0.5872\n",
      "Recall: 0.5824\n",
      "F1 Score: 0.5547\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      0.80      0.89         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.67      0.40      0.50         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.33      0.50         3\n",
      "           N26       0.75      0.69      0.72        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.00      0.00      0.00         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      1.00      1.00         3\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       0.67      1.00      0.80         4\n",
      "  errorMessage       0.40      0.40      0.40         5\n",
      "        fibank       0.00      0.00      0.00         0\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.88      0.70      0.78        10\n",
      "          misc       1.00      0.33      0.50         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "        paypal       0.00      0.00      0.00         0\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.46      1.00      0.63        13\n",
      "      unloaded       0.10      0.11      0.11         9\n",
      "\n",
      "      accuracy                           0.58        91\n",
      "     macro avg       0.40      0.36      0.36        91\n",
      "  weighted avg       0.59      0.58      0.55        91\n",
      "\n",
      "\n",
      "Evaluating Model: CatBoost\n",
      "Accuracy: 0.5824\n",
      "Precision: 0.5767\n",
      "Recall: 0.5824\n",
      "F1 Score: 0.5653\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      0.80      0.89         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.33      0.60      0.43         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.33      0.50         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.50      1.00      0.67         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       0.00      0.00      0.00         3\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.44      0.80      0.57         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.89      0.80      0.84        10\n",
      "          misc       0.00      0.00      0.00         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.75      0.92      0.83        13\n",
      "      unloaded       0.09      0.11      0.10         9\n",
      "\n",
      "      accuracy                           0.58        91\n",
      "     macro avg       0.38      0.39      0.37        91\n",
      "  weighted avg       0.58      0.58      0.57        91\n",
      "\n",
      "\n",
      "Evaluating Model: KNeighborsUnif\n",
      "Accuracy: 0.5714\n",
      "Precision: 0.6328\n",
      "Recall: 0.5714\n",
      "F1 Score: 0.5691\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Advanzia       1.00      1.00      1.00         5\n",
      "AmericanExpress       0.00      0.00      0.00         0\n",
      "     BancoInter       0.75      1.00      0.86         3\n",
      "      CarreBlue       0.00      0.00      0.00         2\n",
      " CirclWebServer       1.00      1.00      1.00         2\n",
      "  CounterStrike       0.25      0.20      0.22         5\n",
      "    EmiratesNBD       0.00      0.00      0.00         1\n",
      "       FrImpots       0.00      0.00      0.00         0\n",
      "            KBC       1.00      0.67      0.80         3\n",
      "            N26       0.88      0.54      0.67        13\n",
      "       Oldcircl       0.25      1.00      0.40         1\n",
      "       OneDrive       0.00      0.00      0.00         1\n",
      "  OrangeWebmail       0.00      0.00      0.00         0\n",
      "        Outlook       0.00      0.00      0.00         0\n",
      "        SPankki       0.50      1.00      0.67         1\n",
      "          Steam       1.00      0.67      0.80         3\n",
      "  TaggingServer       0.00      0.00      0.00         0\n",
      "     WellsFargo       0.00      0.00      0.00         1\n",
      "      ackouperm       1.00      0.75      0.86         4\n",
      "        android       0.00      0.00      0.00         0\n",
      "   errorMessage       1.00      0.20      0.33         5\n",
      "         fibank       0.00      0.00      0.00         0\n",
      "       formular       0.00      0.00      0.00         1\n",
      "         google       0.00      0.00      0.00         1\n",
      "      microsoft       0.89      0.80      0.84        10\n",
      "           misc       0.00      0.00      0.00         3\n",
      "      multilogo       0.00      0.00      0.00         1\n",
      "           news       0.00      0.00      0.00         1\n",
      "         paypal       0.00      0.00      0.00         0\n",
      "      rackspace       0.00      0.00      0.00         2\n",
      "     uncomplete       0.60      0.92      0.73        13\n",
      "       unloaded       0.36      0.44      0.40         9\n",
      "\n",
      "       accuracy                           0.57        91\n",
      "      macro avg       0.33      0.32      0.30        91\n",
      "   weighted avg       0.63      0.57      0.57        91\n",
      "\n",
      "\n",
      "Evaluating Model: WeightedEnsemble_L2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5714\n",
      "Precision: 0.5539\n",
      "Recall: 0.5714\n",
      "F1 Score: 0.5442\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      0.80      0.89         5\n",
      "    BancoInter       0.75      1.00      0.86         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.33      0.40      0.36         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.67      0.80         3\n",
      "           N26       0.80      0.62      0.70        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.00      0.00      0.00         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       0.80      1.00      0.89         4\n",
      "  errorMessage       0.40      0.40      0.40         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.89      0.80      0.84        10\n",
      "          misc       0.50      0.33      0.40         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.50      1.00      0.67        13\n",
      "      unloaded       0.00      0.00      0.00         9\n",
      "\n",
      "      accuracy                           0.57        91\n",
      "     macro avg       0.40      0.39      0.38        91\n",
      "  weighted avg       0.55      0.57      0.54        91\n",
      "\n",
      "\n",
      "Evaluating Model: LightGBMXT\n",
      "Accuracy: 0.5604\n",
      "Precision: 0.5385\n",
      "Recall: 0.5604\n",
      "F1 Score: 0.5283\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      0.80      0.89         5\n",
      "    BancoInter       0.75      1.00      0.86         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.40      0.40      0.40         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.33      0.50         3\n",
      "           N26       0.67      0.62      0.64        13\n",
      "        Office       0.00      0.00      0.00         0\n",
      "      Oldcircl       0.00      0.00      0.00         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      0.67      0.80         3\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       0.80      1.00      0.89         4\n",
      "  errorMessage       0.40      0.40      0.40         5\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.89      0.80      0.84        10\n",
      "          misc       0.50      0.33      0.40         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.50      1.00      0.67        13\n",
      "      unloaded       0.00      0.00      0.00         9\n",
      "\n",
      "      accuracy                           0.56        91\n",
      "     macro avg       0.40      0.37      0.37        91\n",
      "  weighted avg       0.54      0.56      0.53        91\n",
      "\n",
      "\n",
      "Evaluating Model: XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5604\n",
      "Precision: 0.5487\n",
      "Recall: 0.5604\n",
      "F1 Score: 0.5368\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      0.80      0.89         5\n",
      "    BancoInter       0.75      1.00      0.86         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.40      0.40      0.40         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.33      0.50         3\n",
      "           N26       0.82      0.69      0.75        13\n",
      "      Oldcircl       0.00      0.00      0.00         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      " OrangeWebmail       0.00      0.00      0.00         0\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       0.75      1.00      0.86         3\n",
      " TaggingServer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       1.00      1.00      1.00         4\n",
      "  errorMessage       0.33      0.40      0.36         5\n",
      "        fibank       0.00      0.00      0.00         0\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.88      0.70      0.78        10\n",
      "          misc       0.20      0.33      0.25         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.52      0.92      0.67        13\n",
      "      unloaded       0.00      0.00      0.00         9\n",
      "\n",
      "      accuracy                           0.56        91\n",
      "     macro avg       0.36      0.35      0.34        91\n",
      "  weighted avg       0.55      0.56      0.54        91\n",
      "\n",
      "\n",
      "Evaluating Model: LightGBMLarge\n",
      "Accuracy: 0.5385\n",
      "Precision: 0.5707\n",
      "Recall: 0.5385\n",
      "F1 Score: 0.5314\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Advanzia       1.00      0.80      0.89         5\n",
      "    BancoInter       1.00      1.00      1.00         3\n",
      "     CarreBlue       0.00      0.00      0.00         2\n",
      "CirclWebServer       1.00      1.00      1.00         2\n",
      " CounterStrike       0.67      0.40      0.50         5\n",
      "   EmiratesNBD       0.00      0.00      0.00         1\n",
      "           KBC       1.00      0.33      0.50         3\n",
      "           N26       0.73      0.62      0.67        13\n",
      "      Oldcircl       0.00      0.00      0.00         1\n",
      "      OneDrive       0.00      0.00      0.00         1\n",
      " OrangeWebmail       0.00      0.00      0.00         0\n",
      "       Outlook       0.00      0.00      0.00         0\n",
      "       SPankki       1.00      1.00      1.00         1\n",
      "         Steam       1.00      1.00      1.00         3\n",
      "    WeTransfer       0.00      0.00      0.00         0\n",
      "    WellsFargo       0.00      0.00      0.00         1\n",
      "     ackouperm       0.80      1.00      0.89         4\n",
      "  errorMessage       0.67      0.40      0.50         5\n",
      "        fibank       0.00      0.00      0.00         0\n",
      "      formular       0.00      0.00      0.00         1\n",
      "        google       0.00      0.00      0.00         1\n",
      "     microsoft       0.86      0.60      0.71        10\n",
      "          misc       0.00      0.00      0.00         3\n",
      "     multilogo       0.00      0.00      0.00         1\n",
      "          news       0.00      0.00      0.00         1\n",
      "     rackspace       0.00      0.00      0.00         2\n",
      "    uncomplete       0.54      1.00      0.70        13\n",
      "      unloaded       0.00      0.00      0.00         9\n",
      "\n",
      "      accuracy                           0.54        91\n",
      "     macro avg       0.37      0.33      0.33        91\n",
      "  weighted avg       0.57      0.54      0.53        91\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    top_k_accuracy_score,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Prepare DataFrame for AutoGluon using only image embeddings\n",
    "embedding_cols = pd.DataFrame(df[\"text_embedding\"].to_list())\n",
    "embedding_cols.columns = [f\"feature_{i}\" for i in range(embedding_cols.shape[1])]\n",
    "df_for_autogluon = pd.concat([embedding_cols, df[\"brand\"]], axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = df_for_autogluon.sample(frac=0.8, random_state=42)\n",
    "test_data = df_for_autogluon.drop(train_data.index)\n",
    "\n",
    "# Define label column\n",
    "label = \"brand\"\n",
    "\n",
    "# Train AutoGluon model\n",
    "predictor = TabularPredictor(label=label).fit(train_data)\n",
    "\n",
    "# Get leaderboard\n",
    "leaderboard = predictor.leaderboard(test_data, silent=True)\n",
    "print(\"Leaderboard of Models:\")\n",
    "print(leaderboard)\n",
    "\n",
    "# Test labels and data without the label column\n",
    "test_labels = test_data[label]\n",
    "test_data_no_label = test_data.drop(columns=[label])\n",
    "\n",
    "# Unique labels (needed for ROC-AUC alignment)\n",
    "unique_labels = predictor.class_labels\n",
    "\n",
    "# Evaluate each model individually\n",
    "for model_name in leaderboard[\"model\"]:\n",
    "    print(f\"\\nEvaluating Model: {model_name}\")\n",
    "    \n",
    "    # Predict using the specific model\n",
    "    predictions = predictor.predict(test_data_no_label, model=model_name)\n",
    "    probs = predictor.predict_proba(test_data_no_label, model=model_name)\n",
    "\n",
    "    # Ensure alignment of probabilities and labels\n",
    "    probs_aligned = probs.loc[:, unique_labels].to_numpy()\n",
    "    test_labels_binarized = label_binarize(test_labels, classes=unique_labels)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions, average=\"weighted\")\n",
    "    recall = recall_score(test_labels, predictions, average=\"weighted\")\n",
    "    f1 = f1_score(test_labels, predictions, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(test_labels, predictions))\n",
    "\n",
    "# save classification_report(test_labels, predictions)\n",
    "report = classification_report(test_labels, predictions, output_dict=True)\n",
    "pd.DataFrame(report).transpose().to_csv(\"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_text.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with multimodal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.23      0.33        13\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.45      0.83      0.59         6\n",
      "           3       0.36      1.00      0.53         4\n",
      "           4       1.00      1.00      1.00         1\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         3\n",
      "          10       1.00      1.00      1.00         1\n",
      "          11       1.00      1.00      1.00         3\n",
      "          13       1.00      0.92      0.96        13\n",
      "          14       0.75      1.00      0.86         3\n",
      "          15       0.75      1.00      0.86         3\n",
      "          16       0.00      0.00      0.00         4\n",
      "          17       1.00      1.00      1.00         3\n",
      "          18       0.67      1.00      0.80         2\n",
      "          19       1.00      1.00      1.00         1\n",
      "          20       1.00      1.00      1.00         2\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         3\n",
      "          23       1.00      0.50      0.67         2\n",
      "          25       1.00      1.00      1.00         1\n",
      "          26       1.00      1.00      1.00         1\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       0.00      0.00      0.00         1\n",
      "          30       1.00      1.00      1.00         3\n",
      "          31       1.00      0.50      0.67         2\n",
      "          32       0.00      0.00      0.00         1\n",
      "          33       0.67      1.00      0.80         4\n",
      "          36       0.33      1.00      0.50         1\n",
      "          39       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.74        92\n",
      "   macro avg       0.68      0.73      0.68        92\n",
      "weighted avg       0.73      0.74      0.70        92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data for SVM\n",
    "X = df['combined_embedding'].to_list()\n",
    "y = df[\"brand\"].factorize()[0]  # Encode labels\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM\n",
    "svm_model = SVC(kernel=\"linear\", probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate SVM\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "#save report \n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "pd.DataFrame(report).transpose().to_csv(\"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_svm_multimodality.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.23      0.32        13\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.42      0.83      0.56         6\n",
      "           3       0.38      0.75      0.50         4\n",
      "           4       1.00      1.00      1.00         1\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         3\n",
      "          10       1.00      1.00      1.00         1\n",
      "          11       1.00      1.00      1.00         3\n",
      "          13       1.00      0.92      0.96        13\n",
      "          14       0.75      1.00      0.86         3\n",
      "          15       0.75      1.00      0.86         3\n",
      "          16       0.00      0.00      0.00         4\n",
      "          17       1.00      1.00      1.00         3\n",
      "          18       0.67      1.00      0.80         2\n",
      "          19       1.00      1.00      1.00         1\n",
      "          20       1.00      1.00      1.00         2\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         3\n",
      "          23       0.50      0.50      0.50         2\n",
      "          25       1.00      1.00      1.00         1\n",
      "          26       1.00      1.00      1.00         1\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       0.00      0.00      0.00         1\n",
      "          30       1.00      1.00      1.00         3\n",
      "          31       1.00      0.50      0.67         2\n",
      "          32       1.00      1.00      1.00         1\n",
      "          33       0.67      1.00      0.80         4\n",
      "          36       0.33      1.00      0.50         1\n",
      "          39       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.74        92\n",
      "   macro avg       0.70      0.75      0.71        92\n",
      "weighted avg       0.71      0.74      0.70        92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "X = np.hstack([np.vstack(df[\"image_embedding\"])])  # Combine embeddings\n",
    "y = df[\"brand\"].factorize()[0]  # Encode labels\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM\n",
    "svm_model = SVC(kernel=\"linear\", probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate SVM\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "#save report \n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "pd.DataFrame(report).transpose().to_csv(\"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_svm_img.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.23      0.27        13\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.43      1.00      0.60         6\n",
      "           3       0.33      0.75      0.46         4\n",
      "           4       1.00      1.00      1.00         1\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         3\n",
      "          10       1.00      1.00      1.00         1\n",
      "          11       1.00      1.00      1.00         3\n",
      "          13       0.85      0.85      0.85        13\n",
      "          14       0.40      0.67      0.50         3\n",
      "          15       0.60      1.00      0.75         3\n",
      "          16       0.00      0.00      0.00         4\n",
      "          17       1.00      1.00      1.00         3\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       1.00      1.00      1.00         1\n",
      "          20       1.00      1.00      1.00         2\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         3\n",
      "          23       1.00      0.50      0.67         2\n",
      "          25       1.00      1.00      1.00         1\n",
      "          26       1.00      1.00      1.00         1\n",
      "          27       1.00      0.50      0.67         2\n",
      "          28       0.00      0.00      0.00         1\n",
      "          30       1.00      1.00      1.00         3\n",
      "          31       0.00      0.00      0.00         2\n",
      "          32       0.00      0.00      0.00         1\n",
      "          33       0.60      0.75      0.67         4\n",
      "          36       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.67        92\n",
      "   macro avg       0.62      0.64      0.62        92\n",
      "weighted avg       0.63      0.67      0.63        92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "X = np.hstack([np.vstack(df[\"text_embedding\"])])  # Combine embeddings\n",
    "y = df[\"brand\"].factorize()[0]  # Encode labels\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM\n",
    "svm_model = SVC(kernel=\"linear\", probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate SVM\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "#save report \n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "pd.DataFrame(report).transpose().to_csv(\"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_svm_text.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with multimodal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Epoch 1, Loss: 3.2122\n",
      "Epoch 2, Loss: 2.2428\n",
      "Epoch 3, Loss: 1.7214\n",
      "Epoch 4, Loss: 1.3607\n",
      "Epoch 5, Loss: 1.0502\n",
      "Epoch 6, Loss: 0.8116\n",
      "Epoch 7, Loss: 0.6931\n",
      "Epoch 8, Loss: 0.5481\n",
      "Epoch 9, Loss: 0.4075\n",
      "Epoch 10, Loss: 0.3389\n",
      "Epoch 11, Loss: 0.2540\n",
      "Epoch 12, Loss: 0.2506\n",
      "Epoch 13, Loss: 0.1608\n",
      "Epoch 14, Loss: 0.1663\n",
      "Epoch 15, Loss: 0.1062\n",
      "Epoch 16, Loss: 0.1262\n",
      "Epoch 17, Loss: 0.0957\n",
      "Epoch 18, Loss: 0.0935\n",
      "Epoch 19, Loss: 0.0860\n",
      "Epoch 20, Loss: 0.0726\n",
      "Epoch 21, Loss: 0.0777\n",
      "Epoch 22, Loss: 0.0661\n",
      "Epoch 23, Loss: 0.0672\n",
      "Epoch 24, Loss: 0.0583\n",
      "Epoch 25, Loss: 0.0496\n",
      "Epoch 26, Loss: 0.0698\n",
      "Epoch 27, Loss: 0.0626\n",
      "Epoch 28, Loss: 0.0431\n",
      "Epoch 29, Loss: 0.0650\n",
      "Epoch 30, Loss: 0.0655\n",
      "Epoch 31, Loss: 0.0538\n",
      "Epoch 32, Loss: 0.0320\n",
      "Epoch 33, Loss: 0.0445\n",
      "Epoch 34, Loss: 0.0626\n",
      "Epoch 35, Loss: 0.0539\n",
      "Epoch 36, Loss: 0.0735\n",
      "Epoch 37, Loss: 0.0507\n",
      "Epoch 38, Loss: 0.0506\n",
      "Epoch 39, Loss: 0.0555\n",
      "Epoch 40, Loss: 0.0717\n",
      "Epoch 41, Loss: 0.0478\n",
      "Epoch 42, Loss: 0.0529\n",
      "Early stopping triggered.\n",
      "Test Accuracy: 76.09%\n",
      "Precision: 0.7672, Recall: 0.7609, F1 Score: 0.7398\n",
      "Classification report saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/0bwncfpn36z61mb3pf6tlyyh0000gn/T/ipykernel_8372/851279043.py:90: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pth\"))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data for CNN\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]\n",
    "\n",
    "mul_embeddings = np.vstack(df[\"combined_embedding\"])\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(df[\"brand\"])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(mul_embeddings, labels, test_size=0.2, random_state=42)\n",
    "train_dataset = ImageDataset(X_train, y_train)\n",
    "test_dataset = ImageDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define CNN\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Train CNN\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {device}\")\n",
    "model = CNNClassifier(input_dim=mul_embeddings.shape[1], num_classes=len(label_encoder.classes_)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Early stopping parameters\n",
    "best_loss = float('inf')\n",
    "patience = 10\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(1000):  # Max epochs\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    epoch_loss /= len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        early_stop_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")  # Save the best model\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "# Evaluate CNN\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, all_predictions)\n",
    "precision = precision_score(y_test, all_predictions, average=\"weighted\")\n",
    "recall = recall_score(y_test, all_predictions, average=\"weighted\")\n",
    "f1 = f1_score(y_test, all_predictions, average=\"weighted\")\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Save report\n",
    "report = classification_report(y_test, all_predictions, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "# Add overall metrics to the report\n",
    "report_df.loc[\"overall\"] = {\"precision\": precision, \"recall\": recall, \"f1-score\": f1, \"accuracy\": accuracy}\n",
    "report_df.to_csv(\"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_cnn_multimodality.csv\")\n",
    "\n",
    "print(\"Classification report saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Epoch 1, Loss: 3.3001\n",
      "Epoch 2, Loss: 2.4926\n",
      "Epoch 3, Loss: 1.9622\n",
      "Epoch 4, Loss: 1.5636\n",
      "Epoch 5, Loss: 1.3660\n",
      "Epoch 6, Loss: 1.1073\n",
      "Epoch 7, Loss: 0.8743\n",
      "Epoch 8, Loss: 0.7726\n",
      "Epoch 9, Loss: 0.6399\n",
      "Epoch 10, Loss: 0.5087\n",
      "Epoch 11, Loss: 0.4326\n",
      "Epoch 12, Loss: 0.3677\n",
      "Epoch 13, Loss: 0.3163\n",
      "Epoch 14, Loss: 0.2289\n",
      "Epoch 15, Loss: 0.1737\n",
      "Epoch 16, Loss: 0.1666\n",
      "Epoch 17, Loss: 0.1740\n",
      "Epoch 18, Loss: 0.1736\n",
      "Epoch 19, Loss: 0.1331\n",
      "Epoch 20, Loss: 0.1290\n",
      "Epoch 21, Loss: 0.1242\n",
      "Epoch 22, Loss: 0.0959\n",
      "Epoch 23, Loss: 0.0977\n",
      "Epoch 24, Loss: 0.1119\n",
      "Epoch 25, Loss: 0.1140\n",
      "Epoch 26, Loss: 0.0771\n",
      "Epoch 27, Loss: 0.0742\n",
      "Epoch 28, Loss: 0.0834\n",
      "Epoch 29, Loss: 0.0662\n",
      "Epoch 30, Loss: 0.0736\n",
      "Epoch 31, Loss: 0.0666\n",
      "Epoch 32, Loss: 0.0603\n",
      "Epoch 33, Loss: 0.0782\n",
      "Epoch 34, Loss: 0.0853\n",
      "Epoch 35, Loss: 0.0864\n",
      "Epoch 36, Loss: 0.0674\n",
      "Epoch 37, Loss: 0.0590\n",
      "Epoch 38, Loss: 0.0577\n",
      "Epoch 39, Loss: 0.0539\n",
      "Epoch 40, Loss: 0.0791\n",
      "Epoch 41, Loss: 0.0756\n",
      "Epoch 42, Loss: 0.0730\n",
      "Epoch 43, Loss: 0.0579\n",
      "Epoch 44, Loss: 0.0480\n",
      "Epoch 45, Loss: 0.0738\n",
      "Epoch 46, Loss: 0.0533\n",
      "Epoch 47, Loss: 0.0559\n",
      "Epoch 48, Loss: 0.0558\n",
      "Epoch 49, Loss: 0.0680\n",
      "Epoch 50, Loss: 0.0477\n",
      "Epoch 51, Loss: 0.0604\n",
      "Epoch 52, Loss: 0.0384\n",
      "Epoch 53, Loss: 0.0495\n",
      "Epoch 54, Loss: 0.0452\n",
      "Epoch 55, Loss: 0.0546\n",
      "Epoch 56, Loss: 0.0409\n",
      "Epoch 57, Loss: 0.0547\n",
      "Epoch 58, Loss: 0.0455\n",
      "Epoch 59, Loss: 0.0447\n",
      "Epoch 60, Loss: 0.0481\n",
      "Epoch 61, Loss: 0.0404\n",
      "Epoch 62, Loss: 0.0490\n",
      "Early stopping triggered.\n",
      "Test Accuracy: 72.83%\n",
      "Precision: 0.7179, Recall: 0.7283, F1 Score: 0.6843\n",
      "Classification report saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/0bwncfpn36z61mb3pf6tlyyh0000gn/T/ipykernel_8372/2576709328.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pth\"))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "image_embeddings = np.vstack(df[\"image_embedding\"])\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(df[\"brand\"])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_embeddings, labels, test_size=0.2, random_state=42)\n",
    "train_dataset = ImageDataset(X_train, y_train)\n",
    "test_dataset = ImageDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# Train CNN\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {device}\")\n",
    "model = CNNClassifier(input_dim=image_embeddings.shape[1], num_classes=len(label_encoder.classes_)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Early stopping parameters\n",
    "best_loss = float('inf')\n",
    "patience = 10\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(1000):  # Max epochs\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    epoch_loss /= len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        early_stop_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")  # Save the best model\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "# Evaluate CNN\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, all_predictions)\n",
    "precision = precision_score(y_test, all_predictions, average=\"weighted\")\n",
    "recall = recall_score(y_test, all_predictions, average=\"weighted\")\n",
    "f1 = f1_score(y_test, all_predictions, average=\"weighted\")\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Save report\n",
    "report = classification_report(y_test, all_predictions, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "# Add overall metrics to the report\n",
    "report_df.loc[\"overall\"] = {\"precision\": precision, \"recall\": recall, \"f1-score\": f1, \"accuracy\": accuracy}\n",
    "report_df.to_csv(\"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_cnn_image.csv\")\n",
    "\n",
    "print(\"Classification report saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Epoch 1, Loss: 3.3692\n",
      "Epoch 2, Loss: 2.5785\n",
      "Epoch 3, Loss: 2.1604\n",
      "Epoch 4, Loss: 1.8357\n",
      "Epoch 5, Loss: 1.5833\n",
      "Epoch 6, Loss: 1.3058\n",
      "Epoch 7, Loss: 1.1717\n",
      "Epoch 8, Loss: 0.9984\n",
      "Epoch 9, Loss: 0.8585\n",
      "Epoch 10, Loss: 0.7301\n",
      "Epoch 11, Loss: 0.6422\n",
      "Epoch 12, Loss: 0.5354\n",
      "Epoch 13, Loss: 0.4428\n",
      "Epoch 14, Loss: 0.3980\n",
      "Epoch 15, Loss: 0.3449\n",
      "Epoch 16, Loss: 0.3549\n",
      "Epoch 17, Loss: 0.3046\n",
      "Epoch 18, Loss: 0.2890\n",
      "Epoch 19, Loss: 0.3319\n",
      "Epoch 20, Loss: 0.2701\n",
      "Epoch 21, Loss: 0.2278\n",
      "Epoch 22, Loss: 0.2278\n",
      "Epoch 23, Loss: 0.2083\n",
      "Epoch 24, Loss: 0.2545\n",
      "Epoch 25, Loss: 0.2133\n",
      "Epoch 26, Loss: 0.1859\n",
      "Epoch 27, Loss: 0.1967\n",
      "Epoch 28, Loss: 0.1872\n",
      "Epoch 29, Loss: 0.1913\n",
      "Epoch 30, Loss: 0.1865\n",
      "Epoch 31, Loss: 0.1752\n",
      "Epoch 32, Loss: 0.1881\n",
      "Epoch 33, Loss: 0.1824\n",
      "Epoch 34, Loss: 0.1913\n",
      "Epoch 35, Loss: 0.1621\n",
      "Epoch 36, Loss: 0.1696\n",
      "Epoch 37, Loss: 0.1725\n",
      "Epoch 38, Loss: 0.1812\n",
      "Epoch 39, Loss: 0.1784\n",
      "Epoch 40, Loss: 0.1966\n",
      "Epoch 41, Loss: 0.2087\n",
      "Epoch 42, Loss: 0.1850\n",
      "Epoch 43, Loss: 0.1642\n",
      "Epoch 44, Loss: 0.1630\n",
      "Epoch 45, Loss: 0.1632\n",
      "Early stopping triggered.\n",
      "Test Accuracy: 68.48%\n",
      "Precision: 0.6773, Recall: 0.6848, F1 Score: 0.6549\n",
      "Classification report saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/0bwncfpn36z61mb3pf6tlyyh0000gn/T/ipykernel_8372/3056531976.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pth\"))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "text_embeddings = np.vstack(df[\"text_embedding\"])\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(df[\"brand\"])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_embeddings, labels, test_size=0.2, random_state=42)\n",
    "train_dataset = ImageDataset(X_train, y_train)\n",
    "test_dataset = ImageDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# Train CNN\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {device}\")\n",
    "model = CNNClassifier(input_dim=text_embeddings.shape[1], num_classes=len(label_encoder.classes_)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Early stopping parameters\n",
    "best_loss = float('inf')\n",
    "patience = 10\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(1000):  # Max epochs\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    epoch_loss /= len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        early_stop_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")  # Save the best model\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "# Evaluate CNN\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, all_predictions)\n",
    "precision = precision_score(y_test, all_predictions, average=\"weighted\")\n",
    "recall = recall_score(y_test, all_predictions, average=\"weighted\")\n",
    "f1 = f1_score(y_test, all_predictions, average=\"weighted\")\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Save report\n",
    "report = classification_report(y_test, all_predictions, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "# Add overall metrics to the report\n",
    "report_df.loc[\"overall\"] = {\"precision\": precision, \"recall\": recall, \"f1-score\": f1, \"accuracy\": accuracy}\n",
    "report_df.to_csv(\"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_cnn_text.csv\")\n",
    "\n",
    "print(\"Classification report saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running for combined...\n",
      "Epoch 1, Loss: 3.2524\n",
      "Epoch 2, Loss: 2.3090\n",
      "Epoch 3, Loss: 1.7826\n",
      "Epoch 4, Loss: 1.4085\n",
      "Epoch 5, Loss: 1.0808\n",
      "Epoch 6, Loss: 0.8316\n",
      "Epoch 7, Loss: 0.6341\n",
      "Epoch 8, Loss: 0.4804\n",
      "Epoch 9, Loss: 0.3784\n",
      "Epoch 10, Loss: 0.3081\n",
      "Epoch 11, Loss: 0.2290\n",
      "Epoch 12, Loss: 0.2202\n",
      "Epoch 13, Loss: 0.1629\n",
      "Epoch 14, Loss: 0.2075\n",
      "Epoch 15, Loss: 0.1755\n",
      "Epoch 16, Loss: 0.1795\n",
      "Epoch 17, Loss: 0.1671\n",
      "Epoch 18, Loss: 0.1262\n",
      "Epoch 19, Loss: 0.1216\n",
      "Epoch 20, Loss: 0.1466\n",
      "Epoch 21, Loss: 0.1129\n",
      "Epoch 22, Loss: 0.1053\n",
      "Epoch 23, Loss: 0.0860\n",
      "Epoch 24, Loss: 0.0993\n",
      "Epoch 25, Loss: 0.1031\n",
      "Epoch 26, Loss: 0.1170\n",
      "Epoch 27, Loss: 0.0895\n",
      "Epoch 28, Loss: 0.0988\n",
      "Epoch 29, Loss: 0.1066\n",
      "Epoch 30, Loss: 0.0786\n",
      "Epoch 31, Loss: 0.0881\n",
      "Epoch 32, Loss: 0.0801\n",
      "Epoch 33, Loss: 0.0819\n",
      "Epoch 34, Loss: 0.1201\n",
      "Epoch 35, Loss: 0.0957\n",
      "Epoch 36, Loss: 0.0745\n",
      "Epoch 37, Loss: 0.0780\n",
      "Epoch 38, Loss: 0.0843\n",
      "Epoch 39, Loss: 0.0837\n",
      "Epoch 40, Loss: 0.0871\n",
      "Epoch 41, Loss: 0.0770\n",
      "Epoch 42, Loss: 0.0633\n",
      "Epoch 43, Loss: 0.0869\n",
      "Epoch 44, Loss: 0.0849\n",
      "Epoch 45, Loss: 0.0760\n",
      "Epoch 46, Loss: 0.0939\n",
      "Epoch 47, Loss: 0.0726\n",
      "Epoch 48, Loss: 0.0766\n",
      "Epoch 49, Loss: 0.0700\n",
      "Epoch 50, Loss: 0.0706\n",
      "Epoch 51, Loss: 0.0755\n",
      "Epoch 52, Loss: 0.0773\n",
      "Early stopping triggered at epoch 52.\n",
      "Accuracy: 0.7717, Precision: 0.7656, Recall: 0.7717, F1 Score: 0.7481\n",
      "Classification report saved to /Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_mlp_combined.csv\n",
      "\n",
      "Running for image...\n",
      "Epoch 1, Loss: 3.3106\n",
      "Epoch 2, Loss: 2.5343\n",
      "Epoch 3, Loss: 1.9625\n",
      "Epoch 4, Loss: 1.6055\n",
      "Epoch 5, Loss: 1.3115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/0bwncfpn36z61mb3pf6tlyyh0000gn/T/ipykernel_8372/1218722020.py:89: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"best_model_{embedding_type}.pth\"))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 1.1292\n",
      "Epoch 7, Loss: 0.9146\n",
      "Epoch 8, Loss: 0.7483\n",
      "Epoch 9, Loss: 0.6009\n",
      "Epoch 10, Loss: 0.5185\n",
      "Epoch 11, Loss: 0.4611\n",
      "Epoch 12, Loss: 0.3328\n",
      "Epoch 13, Loss: 0.2591\n",
      "Epoch 14, Loss: 0.2392\n",
      "Epoch 15, Loss: 0.2361\n",
      "Epoch 16, Loss: 0.2190\n",
      "Epoch 17, Loss: 0.2095\n",
      "Epoch 18, Loss: 0.1921\n",
      "Epoch 19, Loss: 0.1756\n",
      "Epoch 20, Loss: 0.1295\n",
      "Epoch 21, Loss: 0.1233\n",
      "Epoch 22, Loss: 0.1346\n",
      "Epoch 23, Loss: 0.1118\n",
      "Epoch 24, Loss: 0.1135\n",
      "Epoch 25, Loss: 0.1162\n",
      "Epoch 26, Loss: 0.1197\n",
      "Epoch 27, Loss: 0.1158\n",
      "Epoch 28, Loss: 0.1178\n",
      "Epoch 29, Loss: 0.1059\n",
      "Epoch 30, Loss: 0.1009\n",
      "Epoch 31, Loss: 0.1234\n",
      "Epoch 32, Loss: 0.1430\n",
      "Epoch 33, Loss: 0.1526\n",
      "Epoch 34, Loss: 0.0992\n",
      "Epoch 35, Loss: 0.0876\n",
      "Epoch 36, Loss: 0.0805\n",
      "Epoch 37, Loss: 0.0890\n",
      "Epoch 38, Loss: 0.1053\n",
      "Epoch 39, Loss: 0.0946\n",
      "Epoch 40, Loss: 0.0994\n",
      "Epoch 41, Loss: 0.0763\n",
      "Epoch 42, Loss: 0.0833\n",
      "Epoch 43, Loss: 0.0888\n",
      "Epoch 44, Loss: 0.0713\n",
      "Epoch 45, Loss: 0.0702\n",
      "Epoch 46, Loss: 0.0882\n",
      "Epoch 47, Loss: 0.0881\n",
      "Epoch 48, Loss: 0.0840\n",
      "Epoch 49, Loss: 0.0900\n",
      "Epoch 50, Loss: 0.0852\n",
      "Epoch 51, Loss: 0.0738\n",
      "Epoch 52, Loss: 0.0821\n",
      "Epoch 53, Loss: 0.0866\n",
      "Epoch 54, Loss: 0.0778\n",
      "Epoch 55, Loss: 0.0666\n",
      "Epoch 56, Loss: 0.0824\n",
      "Epoch 57, Loss: 0.0746\n",
      "Epoch 58, Loss: 0.0690\n",
      "Epoch 59, Loss: 0.0766\n",
      "Epoch 60, Loss: 0.0696\n",
      "Epoch 61, Loss: 0.0711\n",
      "Epoch 62, Loss: 0.0748\n",
      "Epoch 63, Loss: 0.0952\n",
      "Epoch 64, Loss: 0.0677\n",
      "Epoch 65, Loss: 0.0985\n",
      "Early stopping triggered at epoch 65.\n",
      "Accuracy: 0.7391, Precision: 0.7155, Recall: 0.7391, F1 Score: 0.7162\n",
      "Classification report saved to /Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_mlp_image.csv\n",
      "\n",
      "Running for text...\n",
      "Epoch 1, Loss: 3.3799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/0bwncfpn36z61mb3pf6tlyyh0000gn/T/ipykernel_8372/1218722020.py:89: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"best_model_{embedding_type}.pth\"))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 2.6299\n",
      "Epoch 3, Loss: 2.2127\n",
      "Epoch 4, Loss: 1.8190\n",
      "Epoch 5, Loss: 1.5981\n",
      "Epoch 6, Loss: 1.3594\n",
      "Epoch 7, Loss: 1.1462\n",
      "Epoch 8, Loss: 1.0008\n",
      "Epoch 9, Loss: 0.8331\n",
      "Epoch 10, Loss: 0.7069\n",
      "Epoch 11, Loss: 0.6221\n",
      "Epoch 12, Loss: 0.5275\n",
      "Epoch 13, Loss: 0.4736\n",
      "Epoch 14, Loss: 0.4133\n",
      "Epoch 15, Loss: 0.4102\n",
      "Epoch 16, Loss: 0.4024\n",
      "Epoch 17, Loss: 0.3907\n",
      "Epoch 18, Loss: 0.3200\n",
      "Epoch 19, Loss: 0.2713\n",
      "Epoch 20, Loss: 0.2913\n",
      "Epoch 21, Loss: 0.2568\n",
      "Epoch 22, Loss: 0.2668\n",
      "Epoch 23, Loss: 0.2608\n",
      "Epoch 24, Loss: 0.2393\n",
      "Epoch 25, Loss: 0.1980\n",
      "Epoch 26, Loss: 0.2549\n",
      "Epoch 27, Loss: 0.1937\n",
      "Epoch 28, Loss: 0.2139\n",
      "Epoch 29, Loss: 0.1902\n",
      "Epoch 30, Loss: 0.1963\n",
      "Epoch 31, Loss: 0.2148\n",
      "Epoch 32, Loss: 0.1897\n",
      "Epoch 33, Loss: 0.2203\n",
      "Epoch 34, Loss: 0.2223\n",
      "Epoch 35, Loss: 0.2275\n",
      "Epoch 36, Loss: 0.2147\n",
      "Epoch 37, Loss: 0.1944\n",
      "Epoch 38, Loss: 0.2063\n",
      "Epoch 39, Loss: 0.2048\n",
      "Epoch 40, Loss: 0.2114\n",
      "Epoch 41, Loss: 0.1938\n",
      "Epoch 42, Loss: 0.1735\n",
      "Epoch 43, Loss: 0.1980\n",
      "Epoch 44, Loss: 0.1989\n",
      "Epoch 45, Loss: 0.1772\n",
      "Epoch 46, Loss: 0.2012\n",
      "Epoch 47, Loss: 0.1806\n",
      "Epoch 48, Loss: 0.2025\n",
      "Epoch 49, Loss: 0.2022\n",
      "Epoch 50, Loss: 0.1972\n",
      "Epoch 51, Loss: 0.2216\n",
      "Epoch 52, Loss: 0.2232\n",
      "Early stopping triggered at epoch 52.\n",
      "Accuracy: 0.6957, Precision: 0.6794, Recall: 0.6957, F1 Score: 0.6753\n",
      "Classification report saved to /Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_mlp_text.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/0bwncfpn36z61mb3pf6tlyyh0000gn/T/ipykernel_8372/1218722020.py:89: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"best_model_{embedding_type}.pth\"))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dataset Class\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]\n",
    "\n",
    "# Define Model\n",
    "class DeepClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(DeepClassifier, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Training and Evaluation Function\n",
    "def train_and_evaluate(embedding_type, embeddings, labels, report_path):\n",
    "    print(f\"\\nRunning for {embedding_type}...\")\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "    train_dataset = EmbeddingDataset(X_train, y_train)\n",
    "    test_dataset = EmbeddingDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Model setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = DeepClassifier(input_dim=embeddings.shape[1], num_classes=len(np.unique(labels))).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Early stopping setup\n",
    "    best_loss = float('inf')\n",
    "    patience = 10\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1000):  # Maximum epochs; early stopping will determine actual limit\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss /= len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            early_stop_counter = 0\n",
    "            torch.save(model.state_dict(), f\"best_model_{embedding_type}.pth\")\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}.\")\n",
    "                break\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(f\"best_model_{embedding_type}.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluation\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_test, all_predictions)\n",
    "    precision = precision_score(y_test, all_predictions, average=\"weighted\")\n",
    "    recall = recall_score(y_test, all_predictions, average=\"weighted\")\n",
    "    f1 = f1_score(y_test, all_predictions, average=\"weighted\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Save report\n",
    "    report = classification_report(y_test, all_predictions, output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_df.loc[\"overall\"] = {\"precision\": precision, \"recall\": recall, \"f1-score\": f1, \"accuracy\": accuracy}\n",
    "    report_df.to_csv(report_path)\n",
    "    print(f\"Classification report saved to {report_path}\")\n",
    "\n",
    "# Prepare Data\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(df[\"brand\"])\n",
    "\n",
    "# Run for each embedding type\n",
    "embedding_types = {\n",
    "    \"combined\": {\"data\": np.vstack(df[\"combined_embedding\"]), \"path\": \"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_mlp_combined.csv\"},\n",
    "    \"image\": {\"data\": np.vstack(df[\"image_embedding\"]), \"path\": \"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_mlp_image.csv\"},\n",
    "    \"text\": {\"data\": np.vstack(df[\"text_embedding\"]), \"path\": \"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_mlp_text.csv\"},\n",
    "}\n",
    "\n",
    "for embedding_type, info in embedding_types.items():\n",
    "    train_and_evaluate(embedding_type, info[\"data\"], labels, info[\"path\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running for combined...\n",
      "Epoch 1, Loss: 3.5954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 3.2525\n",
      "Epoch 3, Loss: 2.9112\n",
      "Epoch 4, Loss: 2.6301\n",
      "Epoch 5, Loss: 2.3628\n",
      "Epoch 6, Loss: 2.1040\n",
      "Epoch 7, Loss: 1.8859\n",
      "Epoch 8, Loss: 1.7143\n",
      "Epoch 9, Loss: 1.5579\n",
      "Epoch 10, Loss: 1.4087\n",
      "Epoch 11, Loss: 1.3030\n",
      "Epoch 12, Loss: 1.1674\n",
      "Epoch 13, Loss: 1.0581\n",
      "Epoch 14, Loss: 0.9728\n",
      "Epoch 15, Loss: 0.8765\n",
      "Epoch 16, Loss: 0.8110\n",
      "Epoch 17, Loss: 0.7525\n",
      "Epoch 18, Loss: 0.6936\n",
      "Epoch 19, Loss: 0.6515\n",
      "Epoch 20, Loss: 0.6067\n",
      "Epoch 21, Loss: 0.5548\n",
      "Epoch 22, Loss: 0.4971\n",
      "Epoch 23, Loss: 0.4704\n",
      "Epoch 24, Loss: 0.4358\n",
      "Epoch 25, Loss: 0.4106\n",
      "Epoch 26, Loss: 0.3965\n",
      "Epoch 27, Loss: 0.3735\n",
      "Epoch 28, Loss: 0.3487\n",
      "Epoch 29, Loss: 0.3143\n",
      "Epoch 30, Loss: 0.2858\n",
      "Epoch 31, Loss: 0.2810\n",
      "Epoch 32, Loss: 0.2566\n",
      "Epoch 33, Loss: 0.2295\n",
      "Epoch 34, Loss: 0.2400\n",
      "Epoch 35, Loss: 0.2493\n",
      "Epoch 36, Loss: 0.2252\n",
      "Epoch 37, Loss: 0.2020\n",
      "Epoch 38, Loss: 0.2181\n",
      "Epoch 39, Loss: 0.2006\n",
      "Epoch 40, Loss: 0.1873\n",
      "Epoch 41, Loss: 0.1989\n",
      "Epoch 42, Loss: 0.1735\n",
      "Epoch 43, Loss: 0.1770\n",
      "Epoch 44, Loss: 0.1670\n",
      "Epoch 45, Loss: 0.1692\n",
      "Epoch 46, Loss: 0.1616\n",
      "Epoch 47, Loss: 0.1663\n",
      "Epoch 48, Loss: 0.1692\n",
      "Epoch 49, Loss: 0.1607\n",
      "Epoch 50, Loss: 0.1688\n",
      "Epoch 51, Loss: 0.1445\n",
      "Epoch 52, Loss: 0.1449\n",
      "Epoch 53, Loss: 0.1324\n",
      "Epoch 54, Loss: 0.1377\n",
      "Epoch 55, Loss: 0.1283\n",
      "Epoch 56, Loss: 0.1251\n",
      "Epoch 57, Loss: 0.1271\n",
      "Epoch 58, Loss: 0.1300\n",
      "Epoch 59, Loss: 0.1154\n",
      "Epoch 60, Loss: 0.1087\n",
      "Epoch 61, Loss: 0.1181\n",
      "Epoch 62, Loss: 0.1194\n",
      "Epoch 63, Loss: 0.1156\n",
      "Epoch 64, Loss: 0.1181\n",
      "Epoch 65, Loss: 0.1239\n",
      "Epoch 66, Loss: 0.1203\n",
      "Epoch 67, Loss: 0.1208\n",
      "Epoch 68, Loss: 0.1214\n",
      "Epoch 69, Loss: 0.1050\n",
      "Epoch 70, Loss: 0.1168\n",
      "Epoch 71, Loss: 0.1246\n",
      "Epoch 72, Loss: 0.1124\n",
      "Epoch 73, Loss: 0.1023\n",
      "Epoch 74, Loss: 0.1101\n",
      "Epoch 75, Loss: 0.0900\n",
      "Epoch 76, Loss: 0.0916\n",
      "Epoch 77, Loss: 0.0856\n",
      "Epoch 78, Loss: 0.1018\n",
      "Epoch 79, Loss: 0.0995\n",
      "Epoch 80, Loss: 0.0904\n",
      "Epoch 81, Loss: 0.1038\n",
      "Epoch 82, Loss: 0.0828\n",
      "Epoch 83, Loss: 0.0934\n",
      "Epoch 84, Loss: 0.0943\n",
      "Epoch 85, Loss: 0.0917\n",
      "Epoch 86, Loss: 0.0876\n",
      "Epoch 87, Loss: 0.0898\n",
      "Epoch 88, Loss: 0.0852\n",
      "Epoch 89, Loss: 0.0933\n",
      "Epoch 90, Loss: 0.0969\n",
      "Epoch 91, Loss: 0.0996\n",
      "Epoch 92, Loss: 0.0998\n",
      "Early stopping triggered at epoch 92.\n",
      "Accuracy: 0.7935, Precision: 0.7778, Recall: 0.7935, F1 Score: 0.7734\n",
      "Classification report saved to /Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_transformer_combined.csv\n",
      "\n",
      "Running for image...\n",
      "Epoch 1, Loss: 3.5833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/0bwncfpn36z61mb3pf6tlyyh0000gn/T/ipykernel_8372/2520677495.py:94: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"best_model_{embedding_type}.pth\"))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 3.2599\n",
      "Epoch 3, Loss: 3.0543\n",
      "Epoch 4, Loss: 2.7720\n",
      "Epoch 5, Loss: 2.5198\n",
      "Epoch 6, Loss: 2.3690\n",
      "Epoch 7, Loss: 2.1089\n",
      "Epoch 8, Loss: 1.9723\n",
      "Epoch 9, Loss: 1.7811\n",
      "Epoch 10, Loss: 1.6507\n",
      "Epoch 11, Loss: 1.5469\n",
      "Epoch 12, Loss: 1.4596\n",
      "Epoch 13, Loss: 1.3807\n",
      "Epoch 14, Loss: 1.2512\n",
      "Epoch 15, Loss: 1.1736\n",
      "Epoch 16, Loss: 1.1164\n",
      "Epoch 17, Loss: 1.0246\n",
      "Epoch 18, Loss: 0.9687\n",
      "Epoch 19, Loss: 0.9285\n",
      "Epoch 20, Loss: 0.8472\n",
      "Epoch 21, Loss: 0.7944\n",
      "Epoch 22, Loss: 0.7233\n",
      "Epoch 23, Loss: 0.7070\n",
      "Epoch 24, Loss: 0.6857\n",
      "Epoch 25, Loss: 0.6180\n",
      "Epoch 26, Loss: 0.5876\n",
      "Epoch 27, Loss: 0.5729\n",
      "Epoch 28, Loss: 0.5334\n",
      "Epoch 29, Loss: 0.4786\n",
      "Epoch 30, Loss: 0.5059\n",
      "Epoch 31, Loss: 0.4488\n",
      "Epoch 32, Loss: 0.4046\n",
      "Epoch 33, Loss: 0.3738\n",
      "Epoch 34, Loss: 0.4071\n",
      "Epoch 35, Loss: 0.3627\n",
      "Epoch 36, Loss: 0.3520\n",
      "Epoch 37, Loss: 0.3285\n",
      "Epoch 38, Loss: 0.2984\n",
      "Epoch 39, Loss: 0.2946\n",
      "Epoch 40, Loss: 0.2716\n",
      "Epoch 41, Loss: 0.2921\n",
      "Epoch 42, Loss: 0.2563\n",
      "Epoch 43, Loss: 0.2542\n",
      "Epoch 44, Loss: 0.2277\n",
      "Epoch 45, Loss: 0.2323\n",
      "Epoch 46, Loss: 0.2187\n",
      "Epoch 47, Loss: 0.2150\n",
      "Epoch 48, Loss: 0.2205\n",
      "Epoch 49, Loss: 0.1962\n",
      "Epoch 50, Loss: 0.1866\n",
      "Epoch 51, Loss: 0.1981\n",
      "Epoch 52, Loss: 0.1882\n",
      "Epoch 53, Loss: 0.1826\n",
      "Epoch 54, Loss: 0.1786\n",
      "Epoch 55, Loss: 0.1702\n",
      "Epoch 56, Loss: 0.1718\n",
      "Epoch 57, Loss: 0.1767\n",
      "Epoch 58, Loss: 0.1545\n",
      "Epoch 59, Loss: 0.1657\n",
      "Epoch 60, Loss: 0.1557\n",
      "Epoch 61, Loss: 0.1614\n",
      "Epoch 62, Loss: 0.1519\n",
      "Epoch 63, Loss: 0.1445\n",
      "Epoch 64, Loss: 0.1260\n",
      "Epoch 65, Loss: 0.1366\n",
      "Epoch 66, Loss: 0.1383\n",
      "Epoch 67, Loss: 0.1376\n",
      "Epoch 68, Loss: 0.1375\n",
      "Epoch 69, Loss: 0.1292\n",
      "Epoch 70, Loss: 0.1185\n",
      "Epoch 71, Loss: 0.1302\n",
      "Epoch 72, Loss: 0.1385\n",
      "Epoch 73, Loss: 0.1289\n",
      "Epoch 74, Loss: 0.1184\n",
      "Epoch 75, Loss: 0.1173\n",
      "Epoch 76, Loss: 0.1146\n",
      "Epoch 77, Loss: 0.1378\n",
      "Epoch 78, Loss: 0.1109\n",
      "Epoch 79, Loss: 0.1055\n",
      "Epoch 80, Loss: 0.1075\n",
      "Epoch 81, Loss: 0.1103\n",
      "Epoch 82, Loss: 0.1012\n",
      "Epoch 83, Loss: 0.1247\n",
      "Epoch 84, Loss: 0.1013\n",
      "Epoch 85, Loss: 0.1039\n",
      "Epoch 86, Loss: 0.1031\n",
      "Epoch 87, Loss: 0.0996\n",
      "Epoch 88, Loss: 0.1034\n",
      "Epoch 89, Loss: 0.0992\n",
      "Epoch 90, Loss: 0.1150\n",
      "Epoch 91, Loss: 0.1082\n",
      "Epoch 92, Loss: 0.0974\n",
      "Epoch 93, Loss: 0.0873\n",
      "Epoch 94, Loss: 0.0957\n",
      "Epoch 95, Loss: 0.0976\n",
      "Epoch 96, Loss: 0.1046\n",
      "Epoch 97, Loss: 0.1230\n",
      "Epoch 98, Loss: 0.0991\n",
      "Epoch 99, Loss: 0.0981\n",
      "Epoch 100, Loss: 0.0976\n",
      "Epoch 101, Loss: 0.1012\n",
      "Epoch 102, Loss: 0.1009\n",
      "Epoch 103, Loss: 0.0838\n",
      "Epoch 104, Loss: 0.0844\n",
      "Epoch 105, Loss: 0.0945\n",
      "Epoch 106, Loss: 0.0880\n",
      "Epoch 107, Loss: 0.0942\n",
      "Epoch 108, Loss: 0.1160\n",
      "Epoch 109, Loss: 0.0724\n",
      "Epoch 110, Loss: 0.0891\n",
      "Epoch 111, Loss: 0.1017\n",
      "Epoch 112, Loss: 0.0874\n",
      "Epoch 113, Loss: 0.0782\n",
      "Epoch 114, Loss: 0.0848\n",
      "Epoch 115, Loss: 0.0895\n",
      "Epoch 116, Loss: 0.0777\n",
      "Epoch 117, Loss: 0.0780\n",
      "Epoch 118, Loss: 0.0871\n",
      "Epoch 119, Loss: 0.1014\n",
      "Early stopping triggered at epoch 119.\n",
      "Accuracy: 0.7609, Precision: 0.7613, Recall: 0.7609, F1 Score: 0.7476\n",
      "Classification report saved to /Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_transformer_image.csv\n",
      "\n",
      "Running for text...\n",
      "Epoch 1, Loss: 3.6358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/0bwncfpn36z61mb3pf6tlyyh0000gn/T/ipykernel_8372/2520677495.py:94: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"best_model_{embedding_type}.pth\"))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 3.3974\n",
      "Epoch 3, Loss: 3.1884\n",
      "Epoch 4, Loss: 3.0139\n",
      "Epoch 5, Loss: 2.7626\n",
      "Epoch 6, Loss: 2.5922\n",
      "Epoch 7, Loss: 2.4007\n",
      "Epoch 8, Loss: 2.2336\n",
      "Epoch 9, Loss: 2.0868\n",
      "Epoch 10, Loss: 1.9423\n",
      "Epoch 11, Loss: 1.8101\n",
      "Epoch 12, Loss: 1.6717\n",
      "Epoch 13, Loss: 1.5736\n",
      "Epoch 14, Loss: 1.4885\n",
      "Epoch 15, Loss: 1.4175\n",
      "Epoch 16, Loss: 1.3052\n",
      "Epoch 17, Loss: 1.2219\n",
      "Epoch 18, Loss: 1.1603\n",
      "Epoch 19, Loss: 1.0831\n",
      "Epoch 20, Loss: 1.0221\n",
      "Epoch 21, Loss: 0.9890\n",
      "Epoch 22, Loss: 0.9126\n",
      "Epoch 23, Loss: 0.8645\n",
      "Epoch 24, Loss: 0.7960\n",
      "Epoch 25, Loss: 0.7641\n",
      "Epoch 26, Loss: 0.7128\n",
      "Epoch 27, Loss: 0.6681\n",
      "Epoch 28, Loss: 0.6555\n",
      "Epoch 29, Loss: 0.6427\n",
      "Epoch 30, Loss: 0.5975\n",
      "Epoch 31, Loss: 0.5209\n",
      "Epoch 32, Loss: 0.5265\n",
      "Epoch 33, Loss: 0.5160\n",
      "Epoch 34, Loss: 0.5130\n",
      "Epoch 35, Loss: 0.4472\n",
      "Epoch 36, Loss: 0.4512\n",
      "Epoch 37, Loss: 0.4419\n",
      "Epoch 38, Loss: 0.4084\n",
      "Epoch 39, Loss: 0.4164\n",
      "Epoch 40, Loss: 0.4123\n",
      "Epoch 41, Loss: 0.3914\n",
      "Epoch 42, Loss: 0.3788\n",
      "Epoch 43, Loss: 0.3771\n",
      "Epoch 44, Loss: 0.3535\n",
      "Epoch 45, Loss: 0.3637\n",
      "Epoch 46, Loss: 0.3434\n",
      "Epoch 47, Loss: 0.3193\n",
      "Epoch 48, Loss: 0.3174\n",
      "Epoch 49, Loss: 0.3109\n",
      "Epoch 50, Loss: 0.3278\n",
      "Epoch 51, Loss: 0.3221\n",
      "Epoch 52, Loss: 0.3128\n",
      "Epoch 53, Loss: 0.2928\n",
      "Epoch 54, Loss: 0.2676\n",
      "Epoch 55, Loss: 0.2693\n",
      "Epoch 56, Loss: 0.2764\n",
      "Epoch 57, Loss: 0.2634\n",
      "Epoch 58, Loss: 0.2836\n",
      "Epoch 59, Loss: 0.2610\n",
      "Epoch 60, Loss: 0.2581\n",
      "Epoch 61, Loss: 0.2600\n",
      "Epoch 62, Loss: 0.2684\n",
      "Epoch 63, Loss: 0.2540\n",
      "Epoch 64, Loss: 0.2398\n",
      "Epoch 65, Loss: 0.2805\n",
      "Epoch 66, Loss: 0.2447\n",
      "Epoch 67, Loss: 0.2632\n",
      "Epoch 68, Loss: 0.2541\n",
      "Epoch 69, Loss: 0.2638\n",
      "Epoch 70, Loss: 0.2676\n",
      "Epoch 71, Loss: 0.2376\n",
      "Epoch 72, Loss: 0.2266\n",
      "Epoch 73, Loss: 0.2158\n",
      "Epoch 74, Loss: 0.2310\n",
      "Epoch 75, Loss: 0.2429\n",
      "Epoch 76, Loss: 0.2610\n",
      "Epoch 77, Loss: 0.2489\n",
      "Epoch 78, Loss: 0.2117\n",
      "Epoch 79, Loss: 0.2091\n",
      "Epoch 80, Loss: 0.2168\n",
      "Epoch 81, Loss: 0.2330\n",
      "Epoch 82, Loss: 0.2143\n",
      "Epoch 83, Loss: 0.2155\n",
      "Epoch 84, Loss: 0.2066\n",
      "Epoch 85, Loss: 0.2086\n",
      "Epoch 86, Loss: 0.1821\n",
      "Epoch 87, Loss: 0.2010\n",
      "Epoch 88, Loss: 0.2187\n",
      "Epoch 89, Loss: 0.2044\n",
      "Epoch 90, Loss: 0.2431\n",
      "Epoch 91, Loss: 0.1873\n",
      "Epoch 92, Loss: 0.2371\n",
      "Epoch 93, Loss: 0.2136\n",
      "Epoch 94, Loss: 0.1965\n",
      "Epoch 95, Loss: 0.2210\n",
      "Epoch 96, Loss: 0.1872\n",
      "Early stopping triggered at epoch 96.\n",
      "Accuracy: 0.7174, Precision: 0.6963, Recall: 0.7174, F1 Score: 0.6938\n",
      "Classification report saved to /Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_transformer_text.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/0bwncfpn36z61mb3pf6tlyyh0000gn/T/ipykernel_8372/2520677495.py:94: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"best_model_{embedding_type}.pth\"))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dataset Class\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]\n",
    "\n",
    "# Define Transformer Model\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, num_heads=8, num_layers=2, hidden_dim=256):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.embedding_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim, nhead=num_heads, dim_feedforward=hidden_dim * 4, dropout=0.3\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding_layer(x)\n",
    "        x = self.transformer_encoder(x.unsqueeze(1)).squeeze(1)  # Add and remove sequence dimension\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Training and Evaluation Function\n",
    "def train_and_evaluate(embedding_type, embeddings, labels, report_path):\n",
    "    print(f\"\\nRunning for {embedding_type}...\")\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "    train_dataset = EmbeddingDataset(X_train, y_train)\n",
    "    test_dataset = EmbeddingDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Model setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = TransformerClassifier(input_dim=embeddings.shape[1], num_classes=len(np.unique(labels))).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "    # Early stopping setup\n",
    "    best_loss = float('inf')\n",
    "    patience = 10\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1000):  # Maximum epochs; early stopping will determine actual limit\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss /= len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            early_stop_counter = 0\n",
    "            torch.save(model.state_dict(), f\"best_model_{embedding_type}.pth\")\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}.\")\n",
    "                break\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(f\"best_model_{embedding_type}.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluation\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_test, all_predictions)\n",
    "    precision = precision_score(y_test, all_predictions, average=\"weighted\")\n",
    "    recall = recall_score(y_test, all_predictions, average=\"weighted\")\n",
    "    f1 = f1_score(y_test, all_predictions, average=\"weighted\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Save report\n",
    "    report = classification_report(y_test, all_predictions, output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_df.loc[\"overall\"] = {\"precision\": precision, \"recall\": recall, \"f1-score\": f1, \"accuracy\": accuracy}\n",
    "    report_df.to_csv(report_path)\n",
    "    print(f\"Classification report saved to {report_path}\")\n",
    "\n",
    "# Prepare Data\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(df[\"brand\"])\n",
    "\n",
    "# Run for each embedding type\n",
    "embedding_types = {\n",
    "    \"combined\": {\"data\": np.vstack(df[\"combined_embedding\"]), \"path\": \"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_transformer_combined.csv\"},\n",
    "    \"image\": {\"data\": np.vstack(df[\"image_embedding\"]), \"path\": \"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_transformer_image.csv\"},\n",
    "    \"text\": {\"data\": np.vstack(df[\"text_embedding\"]), \"path\": \"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_transformer_text.csv\"},\n",
    "}\n",
    "\n",
    "for embedding_type, info in embedding_types.items():\n",
    "    train_and_evaluate(embedding_type, info[\"data\"], labels, info[\"path\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3965871b5d415782d967e85141e3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9082eb93af994abe94f036ab0acf96ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95edad174c3c4d90939b607c2317dd61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3b4241175042448aff8b47ec29834d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7117ace65de44f958980a36064650b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/homebrew/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.5482\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 132\u001b[0m\n\u001b[1;32m    129\u001b[0m texts \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextracted_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# Use extracted text for BERT input\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Train and Evaluate\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreport_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_bert.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[67], line 86\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(texts, labels, report_path)\u001b[0m\n\u001b[1;32m     84\u001b[0m     best_loss \u001b[38;5;241m=\u001b[39m epoch_loss\n\u001b[1;32m     85\u001b[0m     early_stop_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 86\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_bert_model.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     early_stop_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/serialization.py:849\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    846\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 849\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    850\u001b[0m         _save(\n\u001b[1;32m    851\u001b[0m             obj,\n\u001b[1;32m    852\u001b[0m             opened_zipfile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    855\u001b[0m             _disable_byteorder_record,\n\u001b[1;32m    856\u001b[0m         )\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/serialization.py:690\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dataset Class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "# Training and Evaluation Function\n",
    "def train_and_evaluate(texts, labels, report_path):\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "    # Tokenizer and Dataset\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    train_dataset = TextDataset(X_train, y_train, tokenizer)\n",
    "    test_dataset = TextDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    # Model Setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(np.unique(labels)))\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Optimizer and Loss\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training Loop\n",
    "    best_loss = float(\"inf\")\n",
    "    patience = 3\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    for epoch in range(10):  # Maximum epochs\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss /= len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            early_stop_counter = 0\n",
    "            torch.save(model.state_dict(), \"best_bert_model.pth\")\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "    # Load Best Model\n",
    "    model.load_state_dict(torch.load(\"best_bert_model.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluation\n",
    "    all_predictions = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "\n",
    "            all_predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(true_labels, all_predictions)\n",
    "    precision = precision_score(true_labels, all_predictions, average=\"weighted\")\n",
    "    recall = recall_score(true_labels, all_predictions, average=\"weighted\")\n",
    "    f1 = f1_score(true_labels, all_predictions, average=\"weighted\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Save Report\n",
    "    report = classification_report(true_labels, all_predictions, output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_df.loc[\"overall\"] = {\"precision\": precision, \"recall\": recall, \"f1-score\": f1, \"accuracy\": accuracy}\n",
    "    report_df.to_csv(report_path)\n",
    "    print(f\"Classification report saved to {report_path}\")\n",
    "\n",
    "# Prepare Data\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(df[\"brand\"])\n",
    "texts = df[\"extracted_text\"].tolist()  # Use extracted text for BERT input\n",
    "\n",
    "# Train and Evaluate\n",
    "train_and_evaluate(\n",
    "    texts,\n",
    "    labels,\n",
    "    report_path=\"/Volumes/T7/DLCOURSEWORK/circl_phishing_dataset/classification_report_bert.csv\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
